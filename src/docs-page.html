<!DOCTYPE html>
<html lang="en">
<head>
    <title>Vectorly: AI Filters Documentation</title>
    <!-- Meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
	<meta content="Vectorly: AI Filters Documentation" property="og:title">
	<meta
			content="Vectorly's SDK makes it easy to deploy AI filters into WebRTC and video streaming applications"
			name="description">
	<meta content="https://vectorly.io/images/new/ai-compression-temporary.png" property="og:image">

	<meta content="Vectorly: Realtime AI Filters" property="twitter:title">
	<meta
			content="Vectorly's SDK makes it easy to deploy AI filters into WebRTC and video streaming applications"
			property="twitter:description">
	<meta content="https://vectorly.io/images/new/ai-compression-temporary.png" property="twitter:image">

    <meta name="author" content="Vectorly">

	<meta property="og:type" content="website">
	<meta content="summary_large_image" name="twitter:card">

    <link rel="shortcut icon" href="assets/images/vectorly-logo-circle.svg">

    <!-- Google Font -->
    <link href="https://fonts.googleapis.com/css?family=Poppins:300,400,500,600,700&display=swap" rel="stylesheet">

    <!-- FontAwesome JS-->
    <script defer src="assets/fontawesome/js/all.min.js"></script>

    <!-- Plugins CSS -->
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.2/styles/atom-one-dark.min.css">

    <!-- Theme CSS -->
    <link id="theme-style" rel="stylesheet" href="assets/css/theme.css">


	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=UA-134514531-1"></script>
	<script>
		window.dataLayer = window.dataLayer || [];
		function gtag(){dataLayer.push(arguments);}
		gtag('js', new Date());

		gtag('config', 'UA-134514531-1');
	</script>

</head>

<body class="docs-page">
    <header class="header fixed-top">
        <div class="branding docs-branding">
            <div class="container-fluid position-relative py-2">
                <div class="docs-logo-wrapper">
					<button id="docs-sidebar-toggler" class="docs-sidebar-toggler docs-sidebar-visible mr-2 d-xl-none" type="button">
	                    <span></span>
	                    <span></span>
	                    <span></span>
	                </button>
	                <div class="site-logo"><a class="navbar-brand" href="index.html"><img class="logo-icon mr-2" src="assets/images/vectorly-logo-circle.svg" alt="logo"><span class="logo-text">Vectorly<span class="text-alt">&nbsp;Docs</span></span></a></div>
                </div><!--//docs-logo-wrapper-->
	            <div class="docs-top-utilities d-flex justify-content-end align-items-center">

					<ul class="social-list list-inline mx-md-3 mx-lg-5 mb-0 d-none d-lg-flex">
						<li class="list-inline-item"><a href="https://github.com/Vectorly"><i class="fab fa-github fa-fw"></i></a></li>
			            <li class="list-inline-item"><a href="https://www.linkedin.com/company/vectorly"><i class="fab fa-linkedin fa-fw"></i></a></li>
		                <li class="list-inline-item"><a href="https://angel.co/vectorly"><i class="fab fa-angellist fa-fw"></i></a></li>
		            </ul><!--//social-list-->
		            <a href="https://ai-filters.vectorly.io/#/signup" class="btn btn-primary d-none d-lg-flex">Sign up</a>
					<a href="mailto:team@vectorly.io" class="btn btn-outline-primary d-none d-lg-flex" style="margin-left: 20px;">Contact</a>
	            </div><!--//docs-top-utilities-->
            </div><!--//container-->
        </div><!--//branding-->
    </header><!--//header-->

    <div class="docs-wrapper">
	    <div id="docs-sidebar" class="docs-sidebar">
		    <div class="top-search-box d-lg-none p-3">
                <form class="search-form">
		            <input type="text" placeholder="Search the docs..." name="search" class="form-control search-input">
		            <button type="submit" class="btn search-btn" value="Search"><i class="fas fa-search"></i></button>
		        </form>
            </div>
		    <nav id="docs-nav" class="docs-nav navbar">
			    <ul class="section-items list-unstyled nav flex-column pb-3">
				    <li class="nav-item section-title"><a class="nav-link scrollto active" href="#section-intro"><span class="theme-icon-holder mr-2"><i class="fas fa-map-signs"></i></span>Introduction</a></li>
				    <li class="nav-item"><a class="nav-link scrollto" href="#item-installation">Installation</a></li>
				    <li class="nav-item"><a class="nav-link scrollto" href="#item-available-filters">Available Filters</a></li>
				    <li class="nav-item section-title mt-3"><a class="nav-link scrollto" href="#section-background"><span class="theme-icon-holder mr-2"><i class="fas fa-file-code"></i></span>Background Filters</a></li>
					<li class="nav-item"><a class="nav-link scrollto" href="#item-background-loading">Loading</a></li>
					<li class="nav-item"><a class="nav-link scrollto" href="#item-background-basic-usage">Basic Usage</a></li>
					<li class="nav-item"><a class="nav-link scrollto" href="#item-background-support">Browser Support</a></li>
					<li class="nav-item"><a class="nav-link scrollto" href="#item-background-integration">Integration</a></li>
					<li class="nav-item"><a class="nav-link scrollto" href="#item-background-images">Sample Images</a></li>
					<li class="nav-item"><a class="nav-link scrollto" href="#item-background-events">Events</a></li>
					<li class="nav-item"><a class="nav-link scrollto" href="#item-background-controls">Controls</a></li>
					<li class="nav-item"><a class="nav-link scrollto" href="#item-webgl-model">WebGL Model</a></li>

				    <li class="nav-item section-title mt-3"><a class="nav-link scrollto" href="#section-upscaling"><span class="theme-icon-holder mr-2"><i class="fas fa-laptop-code"></i></span>AI Upscaling</a></li>
					<li class="nav-item"><a class="nav-link scrollto" href="#item-upscale-loading">Loading</a></li>
				    <li class="nav-item"><a class="nav-link scrollto" href="#item-upscale-usage">Basic usage</a></li>
				    <li class="nav-item"><a class="nav-link scrollto" href="#item-upscale-integration">Integration</a></li>
				<!--	<li class="nav-item"><a class="nav-link scrollto" href="#item-upscale-ott">HTML5 Players</a></li> -->
				    <li class="nav-item"><a class="nav-link scrollto" href="#item-upscale-events">Events</a></li>
					<li class="nav-item"><a class="nav-link scrollto" href="#item-upscale-controls">Controls</a></li>
					<li class="nav-item"><a class="nav-link scrollto" href="#item-upscale-styling">Styling and Scaling</a></li>
					<li class="nav-item"><a class="nav-link scrollto" href="#item-upscale-models">AI Models</a></li>
					<li class="nav-item"><a class="nav-link scrollto" href="#item-upscale-low-level">Low level controls</a></li>
				    <li class="nav-item section-title mt-3"><a class="nav-link scrollto" href="#section-demos"><span class="theme-icon-holder mr-2"><i class="fas fa-file-video"></i></span>Demos</a></li>
				    <li class="nav-item section-title mt-3"><a class="nav-link scrollto" href="#section-performance"><span class="theme-icon-holder mr-2"><i class="fas fa-chart-bar"></i></span>Performance</a></li>
					<li class="nav-item"><a class="nav-link scrollto" href="#item-background-performance">Background</a></li>
					<li class="nav-item"><a class="nav-link scrollto" href="#item-upscale-performance">Upscaling</a></li>
			    </ul>

		    </nav><!--//docs-nav-->
	    </div><!--//docs-sidebar-->
	    <div class="docs-content">
		    <div class="container">
			    <article class="docs-article" id="section-intro">
				    <header class="docs-header">
					    <h1 class="docs-heading">Introduction <span class="docs-time">Last updated: 2021-06-11</span></h1>
					    <section class="docs-intro" >
							<p>Vectorly's client-side SDK makes it easy to integrate AI filters, such as Background Filters (virtual backgrounds, background blur) as well as AI Upscaling, into WebRTC streaming applications</p>
						</section><!--//docs-intro-->



						<section class="docs-section" id="item-installation">
							<h2 class="section-heading">Installation</h2>




							<p>When you <a href="https://ai-filters.vectorly.io" target="_blank"> sign up</a>, you'll get a <code>token</code> which, you will need to use the library. Next, you can install the ai-filters library via NPM or via CDN</p>


							<p> <b>NPM</b>
								<code><pre>npm install --save @vectorly-io/ai-filters</pre></code>
							</p>

							<p><b>CDN</b>
								<code><pre>https://cdn.vectorly.io/ai-filters/v1/latest/vectorly.filters.js</pre></code></p>
						</section>


						<section class="docs-section" id="item-available-filters">
							<h2 class="section-heading">Available Filters</h2>
							<p>We've compiled a set of AI filters from research & Academia, open source projects as well as our own custom AI filters, all of which are able to be accessed through the same Vectorly interface.</p>
							<h4>Background Filter</h4>



							<p>By using the Background Filter, you can implement features like Virtual Backgrounds or Background Blur, to give users additional privacy when calling from home. The AI model used for running background segmentation is the <code>meet</code> model, used by Google Meet.</p>

							<div style="text-decoration: underline">Background Filters example:</div>
							<figure class="figure docs-figure py-3">


								<div class="table-responsive my-4">
									<table class="table" style="border-color: white">

										<tbody >
										<tr>

											<td style="border-top: white;"><img class="figure-img img-fluid" src="assets/images/videocall-original.png" alt="" style="width: 320px;"></td>
											<td style="border-top: white;"><img class="figure-img img-fluid" src="assets/images/background-blur.png" alt="" style="width: 320px;"></td>
											<td style="border-top: white;"><img class="figure-img img-fluid" src="assets/images/virtual-background.png" alt="" style="width: 320px;"></td>
										</tr>
										<tr style="text-align: center">
											<td style="border-top: white;"><figcaption class="figure-caption mt-3">Original Video Stream</figcaption></td>
											<td style="border-top: white;"><figcaption class="figure-caption mt-3">Background Blur</figcaption></td>
											<td style="border-top: white;"><figcaption class="figure-caption mt-3">Virtual Background</figcaption></td>
										</tr>
										</tbody>
									</table>
								</div>

							</figure>

							<p>See the <a href="#section-background"> Background Filters section</a> for more details</p>


							<h4>Upscaling Filter</h4>
							<p>Vectorly has built it's own AI Upscaling filter based on a technique called <a href="https://en.wikipedia.org/wiki/Super-resolution_imaging">Super Resolution</a>, which uses AI to upscale and enhance images. Through Super Resolution, we can upscale and clean-up low-resolution video, making it look close to HD quality.</p>


							<div style="text-decoration: underline">Super Resolution Example:</div>
							<figure class="figure docs-figure py-3">

								<div class="table-responsive my-4">
									<table class="table" style="border-color: white">

										<tbody >
										<tr>

											<td style="border-top: white;"><img class="figure-img img-fluid" src="assets/images/ducks-240p.png" alt="" style="height: 250px;"></td>
											<td style="border-top: white;"><img class="figure-img img-fluid" src="assets/images/ducks-upscaled.png" alt="" style="height: 250px;"></td>
											<td style="border-top: white;"><img class="figure-img img-fluid" src="assets/images/ducks-720p.png" alt="" style="height: 250px;"></td>
										</tr>
										<tr style="text-align: center">
											<td style="border-top: white;"><figcaption class="figure-caption mt-3">240p</figcaption></td>
											<td style="border-top: white;"><figcaption class="figure-caption mt-3">240p upscaled to 720p</figcaption></td>
											<td style="border-top: white;"><figcaption class="figure-caption mt-3">Original 720p</figcaption></td>
										</tr>
										</tbody>
									</table>
								</div>

							</figure>

							<p>With AI Upscaling, you can improve the clarity & quality of video streams when the source resolution is of low quality.
							</p>

							<figure class="figure docs-figure py-3">
								<img class="figure-img img-fluid" src="assets/images/ai-compression.svg" alt="" style="width: 800px;">
								<!--<figcaption class="figure-caption mt-3"><i class="fas fa-info-circle mr-2"></i>Credit: the above screencast is taken from .</figcaption> -->
							</figure>


								<p>You can also stream SD content to users and upscale it to HD in real time as they're watching it, providing an HD viewing experience while only consuming the bandwidth for the low-resolution video (50 to 90% less data than for the HD video).</p>
							<p>See the <a href="#section-upscaling"> AI Upscaling section</a> for more details</p>


							<h4>Audio Denoise</h4>


							<p>In Development</p>
							<h4>Video Denoise</h4>

							<p>In Development</p>

							<h4>Lighting Correction</h4>

							<p>In Development</p>


						</section><!--//section-->


				    </header>


			    </article>

			    <article class="docs-article" id="section-background">

					<h1 class="docs-heading">Background Filters</h1>


					<p>Our Background filters, based on the Google Meet background segmentaiton model, make it easy to implemet background blur and virtual background features</p>

					<p>You can find a live demo of our virtual background filter <a href="https://files.vectorly.io/demo/background-filter/index.html" target="_blank">here</a></p>

						<h4 class="section-heading"  id="item-background-loading">Loading</h4>

						<p>The basic API for loading the background filter via NPM is:
							<code><pre>

     import { BackgroundFilter } from '@vectorly-io/ai-filters';
					</pre></code>

						</p>


						<p>For loading via CDN, you can access the background filter from the <code>vectorly</code> object


							<code><pre>

     const BackgroundFilter = vectorly.BackgroundFilter;
					</pre></code>


					<p>You can find more detailed loading instructions on the <a href="https://cdn.vectorly.io/ai-filters/docs/latest/">API reference page</a> </p>

					<section class="docs-section"  id="item-background-basic-usage">

						<h4 class="section-heading">Basic Usage</h4>

						<p>Vectorly's Background Filter takes as an input any  <code>MediaStream</code>  or <code>MediaStreamTrack</code> element, so for a WebRTC application, all you need to do is to instantiate the filter object with the  <code>MediaStream</code> or <code>MediaStreamTrack</code>  element you want to filter. The output is a <code>MediaStreamTrack</code>, which can be sent via WebRTC or loaded locally into a <code>video</code> element</p>




						<p>The basic API for loading the background filter is:

							<code><pre>

   const stream = await navigator.mediaDevices.getUserMedia({video:true, audio:true});
   const filter = new BackgroundFilter(stream, {token: 'vectorly-token', background: 'blur'});
   const outputStream =  await filter.getOutput();
					</pre></code>
						</p>


						<p>The above example is for a Background Blur filter. For virtual backgrounds, where you replace the background with an image, the API is:

							<code><pre>

   const filter = new BackgroundFilter(stream, {token: 'vectorly-token', background: 'my-image-url.png'});
					</pre></code>
						</p>



						<p>You can find a full set of methods and parameters on the <a href="https://cdn.vectorly.io/ai-filters/docs/latest/">API reference page</a> </p>


					</section>


					<section class="docs-section"  id="item-background-support">

						<h4 class="section-heading">Browser support</h4>

						<p>

						Our background filters are supported on all major browsers, except for internet explorer. See a table of browser support below
						</p>

						<figure class="figure docs-figure py-3">


							<div class="table-responsive my-4">
								<table class="table" style="border-color: white">

									<tbody >
									<tr>
										<td style="border-top: white;"><img class="figure-img img-fluid" src="assets/images/chrome.svg" alt="" style="width: 50px; margin: auto; display: block; position: relative; opacity: 0;"></td>
										<td style="border-top: white;"><img class="figure-img img-fluid" src="assets/images/chrome.svg" alt="" style="width: 50px; margin: auto; display: block; position: relative;"></td>
										<td style="border-top: white;"><img class="figure-img img-fluid" src="assets/images/safari.svg" alt="" style="width: 50px; margin: auto; display: block; position: relative;"></td>
										<td style="border-top: white;"><img class="figure-img img-fluid" src="assets/images/firefox.svg" alt="" style="width: 50px; margin: auto; display: block; position: relative;"></td>
										<td style="border-top: white;"><img class="figure-img img-fluid" src="assets/images/edge.svg" alt="" style="width: 50px; margin: auto; display: block; position: relative;"></td>
										<td style="border-top: white;"><img class="figure-img img-fluid" src="assets/images/opera.svg" alt="" style="width: 50px; margin: auto; display: block; position: relative;"></td>
										<td style="border-top: white;"><img class="figure-img img-fluid" src="assets/images/ie.svg" alt="" style="width: 50px; margin: auto; display: block; position: relative;"></td>
									</tr>
									<tr style="text-align: center; font-weight: bold;" >
										<td style="border-top: white;"></td>
										<td style="border-top: white;">Chrome</td>
										<td style="border-top: white;">Safari</td>
										<td style="border-top: white;">Firefox</td>
										<td style="border-top: white;">Edge</td>
										<td style="border-top: white;">Opera</td>
										<td style="border-top: white;">IE</td>
									</tr>

									<tr style="text-align: center">
										<td style="border-top: white; font-weight: bold;">WebGL model</td>
										<td style="border-top: white;background: #d3ffd8">Yes</td>
										<td style="border-top: white;background:#ffeccf">Soon (quick fix)</td>
										<td style="border-top: white;background: #d3ffd8">Yes</td>
										<td style="border-top: white;background: #d3ffd8">Yes</td>
										<td style="border-top: white;background: #d3ffd8">Yes</td>
										<td style="border-top: white;background: #ffd7d7">No</td>
									</tr>


									<tr style="text-align: center">
										<td style="border-top: white; font-weight: bold;">Selfie model</td>
										<td style="border-top: white;background: #d3ffd8">Yes</td>
										<td style="border-top: white;background: #d3ffd8">Yes</td>
										<td style="border-top: white;background: #d3ffd8">Yes</td>
										<td style="border-top: white;background: #d3ffd8">Yes</td>
										<td style="border-top: white;background: #d3ffd8">Yes</td>
										<td style="border-top: white;background: #ffd7d7">No</td>
									</tr>

									<tr style="text-align: center">
										<td style="border-top: white; font-weight: bold;">SIMD acceleration*</td>
										<td style="border-top: white; background: #d3ffd8">Yes, since 91</td>
										<td style="border-top: white; background: #ffeccf">No</td>
										<td style="border-top: white;background: #d3ffd8">Yes, since 89</td>
										<td style="border-top: white;background: #d3ffd8">Yes, since 84</td>
										<td style="border-top: white; background: #d3ffd8">Yes, since 77</td>
										<td style="border-top: white;background: #ffd7d7">No</td>
									</tr>



									<tr style="text-align: center">
										<td style="border-top: white; font-weight: bold;">Offscreen Support**</td>
										<td style="border-top: white; background: #d3ffd8">Yes</td>
										<td style="border-top: white; background: #ffeccf">No</td>
										<td style="border-top: white;background: #ffeccf">No</td>
										<td style="border-top: white;background: #d3ffd8">Yes</td>
										<td style="border-top: white; background: #d3ffd8">Yes</td>
										<td style="border-top: white;background: #ffd7d7">No</td>
									</tr>


									</tbody>
								</table>
							</div>

						</figure>


						<p><b>*SIMD acceleration</b></p>
						<p>
							The Google Selfie model uses the CPU. With SIMD acceleration (enabled by default on supported browsers), the CPU usage tends to be ~10% - 15%, whereas if SIMD is not supported, it will take ~30% CPU Usage.



							Recent versions of Chrome, Firefox, Edge and Opera support SIMD acceleration since June 2021.
						</p>


						<p>	<b>**Offscreen Support</b>
							<br/>
							<a href="https://developer.mozilla.org/en-US/docs/Web/API/OffscreenCanvas" >Offscreen support</a> uses OffscreenCanvas to run video-processing workloads in a worker. This both has some performance benefits and is also necessary to continue running the AI filter when the current tab is hidden or minimized.
						</p>


						<div class="callout-block callout-block-info">

							<div class="content">
								<h4 class="callout-title">
	                                <span class="callout-icon-holder mr-1">
		                                <svg class="svg-inline--fa fa-info-circle fa-w-16" aria-hidden="true" focusable="false" data-prefix="fas" data-icon="info-circle" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" data-fa-i2svg=""><path fill="currentColor" d="M256 8C119.043 8 8 119.083 8 256c0 136.997 111.043 248 248 248s248-111.003 248-248C504 119.083 392.957 8 256 8zm0 110c23.196 0 42 18.804 42 42s-18.804 42-42 42-42-18.804-42-42 18.804-42 42-42zm56 254c0 6.627-5.373 12-12 12h-88c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h12v-64h-12c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h64c6.627 0 12 5.373 12 12v100h12c6.627 0 12 5.373 12 12v24z"></path></svg><!-- <i class="fas fa-info-circle"></i> Font Awesome fontawesome.com -->
		                            </span><!--//icon-holder-->
									Note
								</h4>
								<p>		For browsers that do not have Offscreen Support, the filtered stream will pause while the user's tab is hidden / minimized, and will resume again when the user's tab is active again..</p>
							</div><!--//content-->
						</div>




						<p><b>Checking support programatically</b></p>
						<p>You can check if a user's browser supports SIMD acceleration or Offscreen processing via the <a href="https://cdn.vectorly.io/ai-filters/docs/latest/BackgroundFilter.html#.isSupported">`isSupported` API</a> </p>


						<pre><code>
   const isSupported = BackgroundFilter.isSupported(); // False if not supported.
   //If supported, object showing which features are supported.

</code></pre>


					</section>

					<section class="docs-section" id="item-background-integration">
						<h2 class="section-heading">Integration</h2>

						<p>
							Integrating the filter with any specific Video Conferencing API or service just requires finding the <code>MediaStream</code> element associated with video stream you want to filter. The following sub-sections discuss how to integrate the filter with various conferencing services.
						</p>




						<p><b>Vanilla WebRTC</b></p>
						<p>As shown above, the API for basic/general WebRTC is:</p>


						<pre><code>
   const videoTrack = await navigator.mediaDevices.getUserMedia({video:true, audio:true}).getVideoTracks()[0];
   const filter = new BackgroundFilter(videoTrack, { background: 'image.jpg'});
   const virtualBackgroundTrack = await filter.getOutputTrack();

</code></pre>

						<p>You can find a demo repository for vanilla WebRTC background filtering <a href="https://github.com/Vectorly/ai-filters-examples/tree/master/background/webrtc-demo">here</a></p>



						<p><b>Jitsi</b></p>

						<p>You can enable filters on any <code>VideoTrack</code> object by feeding into the Filter's Jitsi Plugin (see <a href="https://jitsi.github.io/handbook/docs/dev-guide/dev-guide-ljm-api#jitsitrack">reference</a>).


						<pre><code>
   const room = connection.initJitsiConference('conference', confOptions);

   JitsiMeetJS.createLocalTracks({devices: ['video']}).then(tracks => {
      const filter = new BackgroundFilter(tracks[0], {token: 'insert-vectorly-token', background: 'blur'});

	filter.getOutput().then(function(filteredStream){
            room.addTrack(filteredStream);
        });

   });


</code></pre>



						<p><b>Agora</b></p>


						<p>For Web deployments using <a href="https://www.agora.io">Agora</a> (specifically the 4.x API), you can just feed the video track to the Background filter, which will return a filtered video track which you can publish.</p>

						<p>
						<pre><code>
    let videoTrack = AgoraRTC.createCameraVideoTrack();
    let audioTrack = AgoraRTC.createMicrophoneAudioTrack();


    const filter = new BackgroundFilter(videoTrack._mediaStreamTrack, {token: 'insert-vectorly-token-here', background: 'blur'});
    filter.getOutputTracj().then(function(filteredTrack ){

       const filteredAgoraTrack = AgoraRTC.createCustomVideoTrack({
         mediaStreamTrack: filteredTrack
       });
      client.publish([filteredAgoraTrack, audioTrack]);
    });

						</code></pre>
						</p>

						<p>You can find a working demo repo <a href="https://github.com/Vectorly/ai-filters-examples/tree/master/background/agora-demo" >here</a></p>



						<p><b>Twilio</b></p>

						<p>You can enable filters on any <code>VideoTrack</code> object by extracting the raw <code>MediaStreamTrack</code>, running the filter on that, and creating a new <code>LocalVideoTrack</code>.


						<pre><code>
   const Twilio = require('twilio-video');

   const localVideoTrack = await Twilio.createLocalVideoTrack();
   const filter = new BackgroundFilter(videoTrack.mediaStreamTrack, {token: 'insert-vectorly-token', background: 'blur'});
   const outputTrack = await filter.getOutputTrack();
   const filteredTrack = new Twilio.LocalVideoTrack(outputTrack);

   room.localParticipant.publishTrack(filteredTrack);

							</code></pre>



						<p><b>Daily.co</b></p>

						<p>If you're building a custom UI with Daily.co, you can use the Daily.co <code>callObject</code>'s  <code>setInputDevices </code> method to set the filtered video track as the upload stream.


						<pre><code>
   const sourceVideoTrack = callObject._participants.local.videoTrack;

   const filter = new vectorly.BackgroundFilter(sourceVideoTrack, {token: 'your-vectorly-token', background: 'https://demo.vectorly.io/virtual-backgrounds/1.jpg'});

   filter.getOutputTrack().then(function(filteredTrack ){

      callObject.setInputDevicesAsync({
         videoSource: filteredTrack
      });

   });
							</code></pre>

						<p>You can find a working example repo <a href="https://github.com/Vectorly/ai-filters-examples/tree/master/background/daily-co-demo" >here</a></p>
						<p><b>Vonage / OpenTok</b></p>

						<p>When you create a <code>Publisher</code> object, just feed the filtered video Track as the video Source


						<pre><code>
   const stream = await navigator.mediaDevices.getUserMedia({video:true, audio:true});
   const filter = new BackgroundFilter(stream, {token: 'vectorly-token', background: 'blur'});
   const outputTrack =  await filter.getOutpuTrack();

   var publisher = OT.initPublisher('publisher', {
      insertMode: 'append',
      width: '100%',
      height: '100%',
      videoSource: outputTrack
   }, handleError);
							</code></pre>


						<p>You can find a working demo repo <a href="https://github.com/Vectorly/ai-filters-examples/tree/master/background/vonage-demo" >here</a></p>

					</section><!--//section-->

<section>
	<p>	<h2 class="section-heading" id="item-background-images">Starter Backgrounds</h2>
	For convenience, if you're interested in adding a virtual backgrounds feature and need some starter images, here are a few:

	</p>

	<figure class="figure docs-figure py-3">

		<div class="table-responsive my-4">
			<table class="table" style="border-color: white">

				<tbody >
				<tr>

					<td style="border-top: white;"><img class="figure-img img-fluid" src="https://demo.vectorly.io/virtual-backgrounds/1.jpg" alt="" style="width: 300px;"></td>
					<td style="border-top: white;"><img class="figure-img img-fluid" src="https://demo.vectorly.io/virtual-backgrounds/2.jpg" alt="" style="width: 300px;"></td>
					<td style="border-top: white;"><img class="figure-img img-fluid" src="https://demo.vectorly.io/virtual-backgrounds/3.jpg" alt="" style="width: 300px;"></td>
				</tr>
				<tr style="text-align: center">
					<td style="border-top: white;"><figcaption class="figure-caption mt-3">https://demo.vectorly.io/virtual-backgrounds/1.jpg</figcaption></td>
					<td style="border-top: white;"><figcaption class="figure-caption mt-3">https://demo.vectorly.io/virtual-backgrounds/2.jpg</figcaption></td>
					<td style="border-top: white;"><figcaption class="figure-caption mt-3">https://demo.vectorly.io/virtual-backgrounds/3.jpg</figcaption></td>
				</tr>


				<tr>

					<td style="border-top: white;"><img class="figure-img img-fluid" src="https://demo.vectorly.io/virtual-backgrounds/4.jpg" alt="" style="width: 300px;"></td>
					<td style="border-top: white;"><img class="figure-img img-fluid" src="https://demo.vectorly.io/virtual-backgrounds/5.jpg" alt="" style="width: 300px;"></td>
					<td style="border-top: white;"><img class="figure-img img-fluid" src="https://demo.vectorly.io/virtual-backgrounds/6.jpg" alt="" style="width: 300px;"></td>
				</tr>
				<tr style="text-align: center">
					<td style="border-top: white;"><figcaption class="figure-caption mt-3">https://demo.vectorly.io/virtual-backgrounds/4.jpg</figcaption></td>
					<td style="border-top: white;"><figcaption class="figure-caption mt-3">https://demo.vectorly.io/virtual-backgrounds/5.jpg</figcaption></td>
					<td style="border-top: white;"><figcaption class="figure-caption mt-3">https://demo.vectorly.io/virtual-backgrounds/6.jpg</figcaption></td>
				</tr>

				<tr>

					<td style="border-top: white;"><img class="figure-img img-fluid" src="https://demo.vectorly.io/virtual-backgrounds/7.jpg" alt="" style="width: 300px;"></td>
					<td style="border-top: white;"><img class="figure-img img-fluid" src="https://demo.vectorly.io/virtual-backgrounds/8.jpg" alt="" style="width: 300px;"></td>
					<td style="border-top: white;"><img class="figure-img img-fluid" src="https://demo.vectorly.io/virtual-backgrounds/9.jpg" alt="" style="width: 300px;"></td>
				</tr>
				<tr style="text-align: center">
					<td style="border-top: white;"><figcaption class="figure-caption mt-3">https://demo.vectorly.io/virtual-backgrounds/7.jpg</figcaption></td>
					<td style="border-top: white;"><figcaption class="figure-caption mt-3">https://demo.vectorly.io/virtual-backgrounds/8.jpg</figcaption></td>
					<td style="border-top: white;"><figcaption class="figure-caption mt-3">https://demo.vectorly.io/virtual-backgrounds/9.jpg</figcaption></td>
				</tr>
				</tbody>
			</table>
		</div>

	</figure>


</section>


					<h2 class="section-heading" id="item-background-events">Events</h2>


					<p>Once you have instantiated the filter object, you can access basic filter events, like onload and error handling.</p>

					<pre>
							 <code>
   const filter = new BackgroundFilter(stream, config);

   filter.on('load', function () {
     console.log("filter initialized");
   });

   filter.on('start', function () {
      console.log("Starting filter");
   });

   filter.on('stop', function () {
      console.log("Stopping filter");
   });

   filter.on('error', function () {
     console.log("Filter failed to initialize");
   });
							 </code>
						 </pre>

					<p>If the filter fails to load, then it will pass through the original video stream</p>


					<h2 class="section-heading" id="item-background-controls">Controls </h2>

					<p> You can enable and disable the filter programatically.</p>

					<pre>
							 <code>
   const filter = new BackgroundFilter(video, config);

   filter.disable();

   filter.enable();
							 </code>
						 </pre>

					<div class="callout-block callout-block-info">

						<div class="content">
							<h4 class="callout-title">
	                                <span class="callout-icon-holder mr-1">
		                                <svg class="svg-inline--fa fa-info-circle fa-w-16" aria-hidden="true" focusable="false" data-prefix="fas" data-icon="info-circle" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" data-fa-i2svg=""><path fill="currentColor" d="M256 8C119.043 8 8 119.083 8 256c0 136.997 111.043 248 248 248s248-111.003 248-248C504 119.083 392.957 8 256 8zm0 110c23.196 0 42 18.804 42 42s-18.804 42-42 42-42-18.804-42-42 18.804-42 42-42zm56 254c0 6.627-5.373 12-12 12h-88c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h12v-64h-12c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h64c6.627 0 12 5.373 12 12v100h12c6.627 0 12 5.373 12 12v24z"></path></svg><!-- <i class="fas fa-info-circle"></i> Font Awesome fontawesome.com -->
		                            </span><!--//icon-holder-->
								Note
							</h4>
							<p>	Calling disable() will stop the filter and return the original MediaStream object by default, and you will need to re-publish the original input MediaStream to the WebRTC client</p>
						</div><!--//content-->
					</div>


					<p>If you want to avoid havinf to re-publish the original media stream, and just have disable/enable toggle the virtual backgrounds on one Media Stream, you can set `passthrough` in the config</p>

					<pre>
							 <code>
   const filter = new BackgroundFilter(video, {token: '...', passthrough: true});

   filter.disable();   // Same media stream, but just doesn't run the background filter

   filter.enable();    // Re-puts in the background filter on the media stream
							 </code>
						 </pre>


					<p> You can also change the inputs to the background filter dynamically</p>


					<pre>
							 <code>
    //Change the background image, or set to "blur" to set a background blur
   await filter.changeBackground("new-background-image.png");


   //Change the source media stream
   const devices = await navigator.mediaDevices.enumerateDevices();
   const alternateWebCam = devices[1]; //Just an example, don't literally copy/paste this
   const alternateWebCamStream  = navigator.getUserMedia({video: {deviceId: alternateWebCam.deviceId}});
   await filter.changeInput(alternateWebCamStream);

							 </code>
						 </pre>

					<p> You can also set the blur level (on a scale of 1 to 10) on initialization, or dynamically with <code>changeBlurRadius</code> method</p>

					<pre>
							 <code>

   const filter = new BackgroundFilter(stream, {token: 'vectorly-token', background: 'blur', blurRadius: 5});
   filter.changeBlurRadius(3);  // 3/10 is less blurry than 5/10

							 </code>
						 </pre>

					<p>You can see a full set of available methods in the <a href="https://cdn.vectorly.io/ai-filters/docs/latest/BackgroundFilter.html">API documentation</a> </p>


					<h2 class="section-heading" id="item-webgl-model">WebGL Model</h2>


					<p>Vectorly's Background SDK provides two AI models for segmentation:  </p>
					<ul>
						<li><a href="https://google.github.io/mediapipe/solutions/selfie_segmentation.html">Google Selfie model</a> (default)</li>
						<li> <a href="#item-webgl-model">Vectorly's own model</a> (beta)</li>
					</ul>


					<p>Our WebGL model is based on MobileNet V3 (similar to the Google Selfie model). While the Google Selfie model is implemented in Web Assembly (which runs on the CPU), Vectorly's model runs in WebGL, meaning the AI model runs on the user's integrated graphics card (or GPU).</p>

					<p>This leads to significantly lower CPU usage for the same quality (see below):</p>

					<figure class="figure docs-figure py-3">
						<img class="figure-img img-fluid" src="assets/images/cpu-usage-background.svg" alt="" style="width: 800px;">
					</figure>

					<div class="callout-block callout-block-info">

						<div class="content">
							<h4 class="callout-title">
	                                <span class="callout-icon-holder mr-1">
		                                <svg class="svg-inline--fa fa-info-circle fa-w-16" aria-hidden="true" focusable="false" data-prefix="fas" data-icon="info-circle" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" data-fa-i2svg=""><path fill="currentColor" d="M256 8C119.043 8 8 119.083 8 256c0 136.997 111.043 248 248 248s248-111.003 248-248C504 119.083 392.957 8 256 8zm0 110c23.196 0 42 18.804 42 42s-18.804 42-42 42-42-18.804-42-42 18.804-42 42-42zm56 254c0 6.627-5.373 12-12 12h-88c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h12v-64h-12c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h64c6.627 0 12 5.373 12 12v100h12c6.627 0 12 5.373 12 12v24z"></path></svg><!-- <i class="fas fa-info-circle"></i> Font Awesome fontawesome.com -->
		                            </span><!--//icon-holder-->
								Note
							</h4>
							<p>The Vectorly WebGL model is currently in Beta, and not enabled by default</p>
						</div><!--//content-->
					</div>


					<p>You can test see a demo of both models <a href="https://files.vectorly.io/demo/background-filter/index.html">here</a>.

						To use it yourself,you can enable it using the <code>model</code> parameter, which you can set to <code>webgl</code> or <code>selfie</code>.


					<p><b>Use the WebGL Model</b>
	<code><pre>

   const filter = new BackgroundFilter(stream, {token: 'vectorly-token', background: 'blur', model: 'webgl'});
					</pre></code>

</p>

					<p><b>Use the Selfie model</b></p>
					<p>Although the Selfie model is loaded by default, you can manually specify the selfie model as so:

						<code><pre>

   const filter = new BackgroundFilter(stream, {token: 'vectorly-token', background: 'blur', model: 'selfie'});
					</pre></code>

					</p>




			    </article><!--//docs-article-->


			    <article class="docs-article" id="section-upscaling">
				    <header class="docs-header">
					    <h1 class="docs-heading">AI Upscaling</h1>

						<h4 class="section-heading"  id="item-upscale-loading">Loading</h4>

						<p> The API for loading the Upscaler is</p>
						<p><b>NPM</b>
							<code><pre>

     import { UpscaleFilter } from '@vectorly-io/ai-filters';
					</pre></code>


						<p>

							<b>CDN</b>
							<code><pre>https://cdn.vectorly.io/ai-filters/v1/latest/vectorly.UpscaleFilter.js</pre></code></p>

						</p>


						<p>For loading via CDN, you can access the upscaling filter as the <code>UpscaleFilter</code> object, which will be available in the global scope





						    <p>For web environments, we've packaged our upscaler as a standalone Javascript library, as well as as plugins to several popular HTML5 video players (see the <a href="https://cdn.vectorly.io/upscaler/docs/latest/">full API</a> for more detail).</p>
					</header>

						<h4 class="section-heading" id="item-upscale-usage">Basic usage</h4>


						 <p>For the <code>UpscaleFilter</code>, the basic API involves instantiating an <code>UpscaleFilter</code> object, and specifying a <code>video</code> element.</p>



						 <pre>
							 <code>
   const video = document.getElementById("video");

   const config = {
	   token: '...'
   };

   const upscaler = new UpscaleFilter(video, config);
							 </code>
						 </pre>


						 <p>This automatically upscales the video, by overlaying a <code>canvas</code> element with the upscaled video frames on top of the <code>video</code> element. When the <code>video</code> plays, the upscaler will automatically upscale each frame and update the <code>canvas</code> element. See the <a href="#item-upscale-styling"> styling</a> section for more detail.</p>




					<section class="docs-section"  id="item-upscale-support">

						<h4 class="section-heading">Browser support</h4>

						<p>

							Our upscaling filters are supported on all major browsers, except for internet explorer. See a table of browser support below
						</p>

						<figure class="figure docs-figure py-3">


							<div class="table-responsive my-4">
								<table class="table" style="border-color: white">

									<tbody >
									<tr>
										<td style="border-top: white;"><img class="figure-img img-fluid" src="assets/images/chrome.svg" alt="" style="width: 50px; margin: auto; display: block; position: relative; opacity: 0;"></td>
										<td style="border-top: white;"><img class="figure-img img-fluid" src="assets/images/chrome.svg" alt="" style="width: 50px; margin: auto; display: block; position: relative;"></td>
										<td style="border-top: white;"><img class="figure-img img-fluid" src="assets/images/safari.svg" alt="" style="width: 50px; margin: auto; display: block; position: relative;"></td>
										<td style="border-top: white;"><img class="figure-img img-fluid" src="assets/images/firefox.svg" alt="" style="width: 50px; margin: auto; display: block; position: relative;"></td>
										<td style="border-top: white;"><img class="figure-img img-fluid" src="assets/images/edge.svg" alt="" style="width: 50px; margin: auto; display: block; position: relative;"></td>
										<td style="border-top: white;"><img class="figure-img img-fluid" src="assets/images/opera.svg" alt="" style="width: 50px; margin: auto; display: block; position: relative;"></td>
										<td style="border-top: white;"><img class="figure-img img-fluid" src="assets/images/ie.svg" alt="" style="width: 50px; margin: auto; display: block; position: relative;"></td>
									</tr>
									<tr style="text-align: center; font-weight: bold;" >
										<td style="border-top: white;"></td>
										<td style="border-top: white;">Chrome</td>
										<td style="border-top: white;">Safari</td>
										<td style="border-top: white;">Firefox</td>
										<td style="border-top: white;">Edge</td>
										<td style="border-top: white;">Opera</td>
										<td style="border-top: white;">IE</td>
									</tr>

									<tr style="text-align: center">
										<td style="border-top: white; font-weight: bold;">Supported</td>
										<td style="border-top: white;background: #d3ffd8">Yes</td>
										<td style="border-top: white;background: #d3ffd8">Yes</td>
										<td style="border-top: white;background: #d3ffd8">Yes</td>
										<td style="border-top: white;background: #d3ffd8">Yes</td>
										<td style="border-top: white;background: #d3ffd8">Yes</td>
										<td style="border-top: white;background: #ffd7d7">No</td>
									</tr>

									</tbody>
								</table>
							</div>

						</figure>


					</section>

					<section class="docs-section" id="item-upscale-integration">


						<h4 class="section-heading">Integration</h4>

						<p ><b>General WebRTC</b></p>


							<p>The <code>UpscaleFilter</code> works with any video tag, so for a WebRTC application, all you need to do is to instantiate the upscaler object with the <code>video</code> element you want to upscale.</p>


							<pre><code>
   const upscaler  = new UpscaleFilter(document.getElementById("remoteVideo"), {token: 'insert-vectorly-token-here'});

</code></pre>

							<p>We have an <a href="https://github.com/Vectorly/webrtc-demo"> example repository</a>, showing how Vectorly can be integrated with WebRTC, as well as a full working general WebRTC demo <a href="https://files.vectorly.io/demo/webrtc/index.html">here.</a> </p>


							<p>
								Integrating the upscaler with any specific Video Conferencing API or service just requires finding the video element associated with video stream you want to upscale.
							</p>


						<p ><b>Jitsi</b></p>

							<p>You can enable upscaling on any <code>VideoTrack</code> object by intercepting the corresponding <code>video</code> element you attach it to (see <a href="https://jitsi.github.io/handbook/docs/dev-guide/dev-guide-ljm-api#jitsitrack">reference</a>).


							<pre><code>
   const room = connection.initJitsiConference('conference', confOptions);
   room.on(JitsiMeetJS.events.conference.TRACK_ADDED, function(track){

      const videoElement = document.createElement('video');
      document.body.appendChild(videoElement);
      track.attach(videoElement);

      const upscaler = new UpscaleFilter(videoElement.current, {token: 'insert-vectorly-token'});

   });
</code></pre>


						<p ><b>Agora</b></p>


							<p>For Web deployments using <a href="https://www.agora.io">Agora</a>, you can find the <code>video</code> element of the stream you want to upscale by using the stream's ID.</p>

							<p>
							<pre><code>
    let stream = AgoraRTC.createStream({
        streamID: uid,
        audio: true,
        video: true,
        screen: false
    });

    stream.init(function() {

        stream.play('target-div');
        const video = document.getElementById("video" + stream.getId());
        const upscaler = new UpscaleFilter(video, {token: 'insert-vectorly-token-here'});

        client.publish(stream);

    });
						</code></pre>
							</p>


						<p ><b>Amazon Chime SDK</b></p>


						<p>For the Amazon Chime SDK, you'll need to use the low <a href="#item-upscale-low-level">level controls library</a>, in conjunction with the <a href="https://aws.github.io/amazon-chime-sdk-js/modules/videoprocessor.html"> Amazon Chime Video Processor API </a></p>

						<p>
						<pre><code>
    if(!this.upscaler){

        this.upscaler = new UpscaleCoreFilter();

        const config = {
          w: frameWidth,
          h: frameHeight,
          renderSize: {w: frameWidth*3, h: frameHeight*3},
          canvas: this.targetCanvas,
          networkParams: {name: 'residual_5k_3x', tag: 'general', version: '0'},
          token: "<your-token>"
        }

       this.upscaler.load(config);

        this.upscaler.on('load', function(){
          this.upscalerReady = true;
        }.bind(this));

    }

    if(this.upscalerReady){
      this.upscaler.setInput(canvas) // Sets input element
      this.upscaler.render() // Renders to canvas
    }

						</code></pre>
						</p>

						<p>The Amazon Chime Video Processor API provides an canvas as your input, and provdes a destination canvas as your output. All you need to do is use the vectorly core library, configure it to render to the output canvas, and feed it the input canvas and render on each render cycle</p>

						<p>The above is a code snipped taken from our full working demo repository, which you can find <a href="https://github.com/Vectorly/ai-filters-examples/tree/feature/ch5400/amazon-chime-integration-documentation/upscaler/amazon-chime-sdk-demo" >here</a> </p>


						<p ><b>Twilio</b></p>

							<p>You can enable upscaling on any <code>VideoTrack</code> object by intercepting the corresponding <code>video</code> element you attach it to (see <a href="https://media.twiliocdn.com/sdk/js/video/releases/2.13.1/docs/VideoTrack.html#attach">reference</a>).



							<p>If you use the <code>track.attach()</code> method to create a <code>video</code> element:</p>


							<pre><code>
   const Video = require('twilio-video');

   Video.createLocalVideoTrack().then(function(videoTrack) {
     const videoElement = videoTrack.attach();
     document.body.appendChild(videoElement);
     const upscaler = new UpscaleFilter(videoElement.current, {token: 'insert-vectorly-token'});
   });
							</code></pre>



							<p>If you specify your own <code>video</code> element:</p>


							<pre><code>
   const Video = require('twilio-video');

   const videoElement = document.createElement('video');
   document.body.appendChild(videoElement);

   Video.createLocalVideoTrack().then(function(videoTrack) {
     videoTrack.attach(videoElement);
     const upscaler = new UpscaleFilter(videoEl.current, {token: 'insert-vectorly-token'});
   });
							</code></pre>



						<p ><b>OpenTok / Vonage</b></p>

							<p>When a <code>Subscriber</code> or <code>Publisher</code> creates a <code>video</code> element you can intercept it and feed that video to the Vectorly Upscaler.



							<p>You can use the <code>subscriber.element</code> property to intercept the video element</p>


							<pre><code>
    session.on('streamCreated', function(event) {

        const subscriber = session.subscribe(event.stream, 'subscriber', {
            insertMode: 'append',
            width: '100%',
            height: '100%'
        }, handleError);

        subscriber.on('videoElementCreated', function (){
            const video = subscriber.element.querySelector('video');
            const upscaler  = new UpscaleFilter(video, {token: '..your-token....'});

        });

    });
							</code></pre>


							<p>This also works with a publisher object. Refer to the <a href="https://tokbox.com/developer/guides/customize-ui/js/">Vonage documentation</a>  for styling - Vectorly's upscaler will fit within the styling defined by OpenTok.</p>

							<p>See our example repistory for a <a href="https://github.com/Vectorly/ai-upscaler-examples/tree/master/vonage-demo"> working code example </a></p>

						<p ><b>Daily.co</b></p>
							<p>You can integrate Vectorly's AI upscaler with <a href="daily.co">Daily.co</a> if you're building a custom <a href="https://docs.daily.co/docs/build-a-custom-video-chat-interface">custom video chat interface </a>. Using the default React code sample from Daily, we've built a full working <a href="https://github.com/Vectorly/daily-call-object/">demo reference</a> </p>


							<pre><code>
   useEffect(() => {
	videoEl.current &&
	(videoEl.current.srcObject = new MediaStream([videoTrack]));
	if (videoEl.current && props.isLarge) {
	window.upscalers = window.upscalers || {}
	window.upscalers[videoTrack.id] = new UpscaleFilter(videoEl.current, {token: 'insert-vectorly-token'});
	}
   }, [videoTrack]);
							</code></pre>

							<p>You just need to make sure you intercept the <code>video</code> element associated with the video track you want to upscale.</p>

							<p>Vectorly's AI upscaler is not compatible with the pre-built UI from Daily.co, as the pre-built UI is loaded via iframe, making it impossible to access the <code>video</code> element through a third party application.</p>


						<p><b>Electron</b></p>


						<p>If you're building an electron app, the Vectorly library is fairly plug and play, and will work with either CDN or NPM installation. </p>

						<p>You can see a demo electron app repostory <a href="https://github.com/Vectorly/vectorly-electron-demo">here</a></p>




					</section>
<!--
						<h4 class="section-heading" id="item-upscale-ott">Plugins</h4>
						Besides the <code>UpscaleFilter</code> module, we have several plugins for specific HTML5 players. (see the <a href="https://cdn.vectorly.io/upscaler/docs/latest/">full API</a> for more detail).


						<p>

						<h4>VideoJS</h4>
						<pre>
							 <code>
   const player = videojs('my-video')
   videojs.registerPlugin('vectorlyPlugin', UpscaleFilter.videoJSPlugin);
   const vjsUpscaler = player.vectorlyPlugin({token: '...'})
							 </code>
						 </pre>

						</p>





						<p>

						<h4>Shaka player</h4>
						<pre>
							 <code>
    async function init() {
       const video = document.getElementById('my-video');
       const ui = video['ui'];
       const controls = ui.getControls();
       const player = controls.getPlayer();

       try {
           await player.load(url);
           // This runs if the asynchronous load is successful.
           const upscaler = new UpscaleFilter.shakaPlugin(player,{
                token: '...'
              });
       } catch (error) {
          console.log(error);
       }
    }

    document.addEventListener('shaka-ui-loaded', init);
							 </code>
						 </pre>

						</p>



					<h4>Custom plugin</h4>

					You can easily build a plugin for Vectorly for any HTML5 video player. All you really need is the <code>video</code> tag, and the video container <code>div</code>, which contains the video UI elements and which is used for <a href="#item-upscale-styling">styling and layout</a>. See a demo plugin code, off of which our other HMTL5 Player plugins are based
					<pre>
							 <code>
   import {UpscaleFilter} from '@vectorly-io/ai-upscaler';

   class myPlugin {

     constructor(videoElement, config){

       const container = videoElement.parentNode; // Or whatever the video container div is
       const upscaler = new UpscaleFilter(videoElement, config);
       this.upscaler = upscaler;

     }

     on(event, callback){
       this.upscaler.on(event, callback)
     }

     enable(){
       this.upscaler.enable();
     }

     disable(){
       this.upscaler.disable();
     }

     changeNetwork(networkParams) {
         this.upscaler.changeNetwork(networkParams)
     }
   }

   export default myPlugin
							 </code>
						 </pre>

					</p>


 -->
						<h2 class="section-heading" id="item-upscale-events">Events</h2>


						<p>Once you have instantiated the upscaler object, you can access basic upscaler events, like onload and error handling.</p>

						<pre>
							 <code>
   const upscaler = new UpscaleFilter(video, config);

   upscaler.on('load', function () {
     console.log("Upscaler initialized");
   });

   upscaler.on('start', function () {
      console.log("Starting upscaling");
   });

   upscaler.on('stop', function () {
      console.log("Stopping upscaling");
   });

   upscaler.on('error', function () {
     console.log("Failed to initialize");
   });
							 </code>
						 </pre>


						<h2 class="section-heading" id="item-upscale-controls">Controls </h2>

						<p> You can also enable and disable the upscaler programatically.</p>

						<pre>
							 <code>
   const upscaler = new UpscaleFilter(video, config);

   upscaler.disable();

   upscaler.enable();
							 </code>
						 </pre>



					<h2 class="section-heading" id="item-upscale-styling">Styling and Scaling</h2>

						<p>

							Let's say you have a video element, inside of a basic container div.

							<code><pre>

   &lt;div id=&quot;container&quot;&gt;
      &lt;video src="video.mp4" &gt;&lt;/video&gt;
   &lt;/div&gt;
				</pre></code>
</p>


					<p>
					When you feed that  <code>video</code> element to the Upcaler instantiation function, it will create a <code>canvas</code> element as a sibling node, with the same parent node as the <code>video</code> element.

						<code><pre>

     &lt;div id=&quot;container&quot;&gt;
         &lt;video src=&quot;video.mp4&quot;  style=&quot;visibility: hidden&quot;&gt;&lt;/video&gt;
         &lt;canvas  id=&quot;output&quot; &gt;&lt;/canvas&gt;  // Where the upscaled frames are drawn
      &lt;/div&gt;
				</pre></code>
					The upscaler library styles this canvas to occupy 100% of the width and height of the parent element, which in practice, covers the video element in most HTML5 video player interfaces.

					</p>

					<p>
							To have more control over the styling and position of the output, you can use the <code>container</code>option, to specify a div element to place the destination canvas.
							<code>
								<pre>


   const video = document.getElementById("video");
   const div = document.getElementById("my-div");

   const config = {
	   token: '...',
	   container:  div //Any div element,
   };

   const upscaler = new UpscaleFilter(video, config);
				</pre></code>

					The output canvas will occupy the exact dimensions of the container div, and will dynamically resize and re-position whenever the container div is moved, resized or changed. To dynamically style and position the output therefore, you should style and position the container element.
						</p>






						<h2 class="section-heading" id="item-upscale-models">Models</h2>

						<p>There are multiple AI models you can choose from. The default is 'residual_3k_3x', but you can specify a model when instantiating the upscaler object
						<pre><code>
   const upscaler = new UpscaleFilter(video, {token: '...', networkParams: { name: 'residual_3k_3x', tag: 'general', version: '2.1'}});
							 </code></pre>
						We are constantly releasing new models. You can find a comprehensive list of models <a href="https://cdn.vectorly.io/upscaler/docs/latest/global.html#NetworkParams" >here</a>




					<br></br>


					<h2 class="section-heading" id="item-upscale-low-level">Low level controls</h2>

					<p>For use cases where lower level control is needed, such as upscaling indidual frames or images, using a custom decoder or upscaling as part of a broader image processing pipeline, you can use the <a href="https://cdn.vectorly.io/upscaler/docs/latest/vectorlyUpscalerCore.html">vectorly-core library</a>.</p>

					<p>With the low level upscaling API, you have control over</p>
					<ul>
						<li>The Input source</li>
						<li>The destination</li>
						<li>When rendering happens</li>
					</ul>



					<p>
					<b>Loading</b></p>

					<p> The API for loading the Core Upscaler is</p>
					<p>NPM
						<code><pre>

     import { UpscaleCoreFilter } from '@vectorly-io/ai-filters';
					</pre></code>


					<p>

						CDN
						<code><pre>https://cdn.vectorly.io/ai-filters/v1/latest/vectorly.UpscaleCoreFilter.js</pre></code></p>

					</p>



					<p><strong>Setting a destination</strong></p>
					<p>Each Upscaler object is tied to an individual <code>canvas</code> element, and renders to that <code>canvas</code> element.</p>
					<p>You specify the <code>canvas</code> element you want to render the upscales to via the upscaler constructor</p>
					<pre><code>
   const upscaler = new UpscaleCoreFilter();
   await upscaler.load({w: videoWidth,
	          h: videoHeight,
	          renderSize: {w: videoWidth*2, h: videoHeight*2},
	          canvas: document.getElementById('your-canvas-element'),
	          networkParams : {name: 'model-name', tag: 'model-tag', version: 'model-version'},
	          token: "your-token"});
					</code></pre>

					<p>The load function returns a promise, which is fulfilled when the upscaler loads, and is rejected when it fails to load.
					This is **on top** of the regular <code>on('load')</code>  and <code>on('error')</code> behavior, so you can either use the promise or the load/error events for flow control and/or error handling
					</p>

					<p>If you want to upscale multiple streams to different canvases, you will need to define a seperate upscaler for each <code>canvas</code> element.</p>
					<p><strong>Setting an input</strong></p>
					<p>At any time, you can set the input of the upscaler via the <code>upscaler.setInput()</code> method</p>
					<pre><code> upscaler.setInput(source); // Sets input element
</code></pre>
					<p>Accepted sources include</p>
					<ul>
						<li><code>HTMLImageElement</code></li>
						<li><code>HTMLCanvasElement</code></li>
						<li><code>HTMLVideoElement</code></li>
						<li><code>ImageData</code></li>
						<li><code>ImageBitmap</code></li>
						<li>Anything else that the <a href="https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/texImage2D" rel="nofollow">texImage2d</a> function accepts</li>
					</ul>

					<div class="callout-block callout-block-info">

						<div class="content">
							<h4 class="callout-title">
	                                <span class="callout-icon-holder mr-1">
		                                <svg class="svg-inline--fa fa-info-circle fa-w-16" aria-hidden="true" focusable="false" data-prefix="fas" data-icon="info-circle" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" data-fa-i2svg=""><path fill="currentColor" d="M256 8C119.043 8 8 119.083 8 256c0 136.997 111.043 248 248 248s248-111.003 248-248C504 119.083 392.957 8 256 8zm0 110c23.196 0 42 18.804 42 42s-18.804 42-42 42-42-18.804-42-42 18.804-42 42-42zm56 254c0 6.627-5.373 12-12 12h-88c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h12v-64h-12c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h64c6.627 0 12 5.373 12 12v100h12c6.627 0 12 5.373 12 12v24z"></path></svg><!-- <i class="fas fa-info-circle"></i> Font Awesome fontawesome.com -->
		                            </span><!--//icon-holder-->
								Note
							</h4>
							<p>The architecture of the Neural Network is such that it will expect a fixed-side input (the one specified in the load function) during your render cycle. If you provide inputs different from the input size, the inputs will be resized to the fixed input resolution.

							</p>
						</div><!--//content-->
					</div>




					<p><strong>Rendering</strong></p>
					<p>Finally, you can render using</p>
					<pre><code>upscaler.render();
</code></pre>
					<p>Which will run the AI upscaling process on the canvas</p>
					<p><strong>Styling &amp; Scaling</strong></p>
					<p>You need to set the input width and height of your input image or video streaming using the <code>w</code> and <code>h</code> properties in the constructor.</p>
					<p>Based on whether you are using  a 2X network, or 3X network, it will set the canvas.width and canvas.height property to 2x or 3x the specified <code>w</code> and <code>h</code>.</p>
					<p>If you want your canvas to be displayed at anything other than <code>2*w</code>by <code>2*h</code> on the screen, you should use CSS styling.</p>
					<pre><code>canvas.style.width = desiredWidth + "px";
canvas.style.height = desiredheight + "px";
</code></pre>
					<p>The browser will still upscale the image from <code>wxh</code> to  <code>2*w x 2*h</code>, but will then use CSS styling &amp; scaling (bicubic scaling) to scale the final output to the  height/width you specify via CSS.</p>




				</article><!--//docs-article-->


			    <article class="docs-article" id="section-demos">
				    <header class="docs-header">
					    <h1 class="docs-heading">Demos</h1>
					    <section class="docs-intro ">

							<p><b>Virtual Background demo</b></p>
							<p><a href="https://files.vectorly.io/demo/background-filter/index.html" target="_blank">Live Virtual Background Demo</a> </p>


							<b>AI Upscaling demos</b>


							<ul>
								<li> <a href="https://files.vectorly.io/demo/docs-demos/demo.html#jellyfish" target="_blank">Jellyfish</a></li>
								<li> <a href="https://files.vectorly.io/demo/docs-demos/demo.html#ducks" target="_blank">Ducks</a></li>
								<li> <a href="https://files.vectorly.io/demo/docs-demos/demo.html#tractor" target="_blank">Tractor</a></li>
								<li> <a href="https://files.vectorly.io/demo/docs-demos/demo.html#fish" target="_blank">Fish</a></li>

							</ul>


						</section><!--//docs-intro-->

				    </header>

			    </article><!--//docs-article-->


		        <article class="docs-article" id="section-performance">
				    <header class="docs-header">
					    <h1 class="docs-heading">Performance</h1>
					    <section class="docs-intro">
						    <p>When running AI filters on client-devices, the most practical challenge is client side performance, as it requires doing large numbers of computations. This can especially become an issue when dealing with low-end devices (such as entry-level smartphones).
							</p>

							<p>	Accordingly, we have focused a great deal on making our AI models as efficient as possible, to enable good quality outputs while still maintaining good client-side rendering performance on low-end devices.
							</p>
						</section><!--//docs-intro-->
				    </header>

					<section class="docs-section" id="item-background-performance">

						<h2 class="section-heading">Background Segmentation</h2>
						<p>Vectorly's Background SDK provides two AI models for segmentation:  </p>
							<ul>
						<li>The		<a href="https://google.github.io/mediapipe/solutions/selfie_segmentation.html">Google Selfie model</a>, implemented in Media Pipe</li>
								<li> <a href="#item-webgl-model">Vectorly's own model</a>, and implemented in WebGL</li>
					</ul>



						<p> Vectorly's <a href="#item-webgl-model">WebGL model</a> has uses significantly less CPU usage than any existing alternative, as the computation is done on the device's integrated graphics card (via WebGL).
						</p>



						<figure class="figure docs-figure py-3">
							<img class="figure-img img-fluid" src="assets/images/cpu-usage-background.svg" alt="" style="width: 800px;">
						</figure>

						<div class="callout-block callout-block-info">

							<div class="content">
								<h4 class="callout-title">
	                                <span class="callout-icon-holder mr-1">
		                                <svg class="svg-inline--fa fa-info-circle fa-w-16" aria-hidden="true" focusable="false" data-prefix="fas" data-icon="info-circle" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" data-fa-i2svg=""><path fill="currentColor" d="M256 8C119.043 8 8 119.083 8 256c0 136.997 111.043 248 248 248s248-111.003 248-248C504 119.083 392.957 8 256 8zm0 110c23.196 0 42 18.804 42 42s-18.804 42-42 42-42-18.804-42-42 18.804-42 42-42zm56 254c0 6.627-5.373 12-12 12h-88c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h12v-64h-12c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h64c6.627 0 12 5.373 12 12v100h12c6.627 0 12 5.373 12 12v24z"></path></svg><!-- <i class="fas fa-info-circle"></i> Font Awesome fontawesome.com -->
		                            </span><!--//icon-holder-->
									Note
								</h4>
								<p>The Background SDK will use the Google Selfie model by default </p>
							</div><!--//content-->
						</div>



						You can see sample profiling results for the Google Selfie model, and the Vectorly WebGL model run on the same input webcam at 30fps</p>

						<figure class="figure docs-figure py-3">

							<div class="table-responsive my-4">
								<table class="table" style="border-color: white">

									<tbody >
									<tr>

										<td style="border-top: white;"><img class="figure-img img-fluid" src="assets/images/selfie-perf.png" alt="" ></td>

										<td style="border-top: white;"><img class="figure-img img-fluid" src="assets/images/vectorly-webg-perf.png" alt=""></td>
									</tr>
									<tr style="text-align: center">
										<td style="border-top: white;"><figcaption class="figure-caption mt-3">Google Selfie (with SIMD acceleration)</figcaption></td>
										<td style="border-top: white;"><figcaption class="figure-caption mt-3">Vectorly WebGL</figcaption></td>
									</tr>
									</tbody>
								</table>
							</div>

						</figure>

						<p>These tests were run on a 2021 Dell XPS 13, with 11th Generation Core i7 processors. You can verify performance for yourself on any deivce with a profiling tool like Google Chrome's <a href="https://developer.chrome.com/docs/devtools/evaluate-performance/reference/"> performance profiler</a>. </p>


						<p id="item-performance-api"><b>Performance API</b></p>

						<p>For checking the performance on a given device, you can use the static <code>checkPerformance</code> method without actually instantiating it on a screen.</p>

						<pre>
							 <code>
     const performanceResults  = await BackgroundFilter.checkPerformance({token: '...'});
							 </code>
						 </pre>



						<p>This cycle through a 720p input for 2 seconds and return an object with the following fields</p>

						<pre>
							 <code>
	{
	  "inputSize": "1280x720",
	  "frameCount": Number,
	  "time": Number,
	  "fps": Number
	}
							 </code>
						 </pre>

						<p>You can also measure the live fps on any given stream by adding the <code>analyticsEnabled</code> flag as <code>true</code> in the configuration parameters.





						<pre>
							 <code>
  const config = {
	   token: '...',
	   background: 'blur',
	   analyticsEnabled: true
   };

   const filter = BackgroundFilter(video, config);
							 </code>
						 </pre>

						</p>


						<div class="callout-block callout-block-info">

							<div class="content">
								<h4 class="callout-title">
	                                <span class="callout-icon-holder mr-1">
		                                <svg class="svg-inline--fa fa-info-circle fa-w-16" aria-hidden="true" focusable="false" data-prefix="fas" data-icon="info-circle" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" data-fa-i2svg=""><path fill="currentColor" d="M256 8C119.043 8 8 119.083 8 256c0 136.997 111.043 248 248 248s248-111.003 248-248C504 119.083 392.957 8 256 8zm0 110c23.196 0 42 18.804 42 42s-18.804 42-42 42-42-18.804-42-42 18.804-42 42-42zm56 254c0 6.627-5.373 12-12 12h-88c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h12v-64h-12c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h64c6.627 0 12 5.373 12 12v100h12c6.627 0 12 5.373 12 12v24z"></path></svg><!-- <i class="fas fa-info-circle"></i> Font Awesome fontawesome.com -->
		                            </span><!--//icon-holder-->
									Note
								</h4>
								<p>		Setting analyticsEnabled to true will also load <a href="https://github.com/segmentio/analytics.js/" >analytics.js</a>, which itself loads a version of Sentry.js, and sends anonymous performance data back to our servers. </p>
							</div><!--//content-->
						</div>


						<h4  id="item-background-performance-considerations">Performance Considerations</h4>

						<p>The performance of the Background Filter (whichever model) is largely dependant on the the following 2 factors</p>

						<ul>
							<li>Resolution</li>
							<li>Framerate</li>
						</ul>

						<p>If you are seeing dropped frames or laggy performance, the main recommendations would be to keep the resolution low (360p or 480p), or to restrict the framerate. You can adjust these settings either directly in the source video <a href="https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices/getUserMedia"> stream</a> or by specifying it in the Vectorly Filter Config:

						<pre>
							 <code>
  const config = {
	   token: '...',
	   background: 'blur',
	   width: ...,
	   height: ...,
	   frameRate: ...,
	   segmentationFrameRate: ...
   };

   const filter = BackgroundFilter(video, config);
							 </code>
						 </pre>

						</p>


						<p>The framerate is the framerate at which the whole video filter is processed, whereas the segmentation Framerate controls how often the segmentation is done. You can do the segmentation less often (say, at 15fps) on a 30fps stream, without noticeable visual impact for the user.</p>

						<p>You can find more information about config options in the <a href="https://cdn.vectorly.io/ai-filters/docs/latest/BackgroundFilter.html">API documentation</a></p>

						<p><b>Performance Bottlenecks</b></p>
						<p>As an explanation of where performance issues may arise, the Background filter consists of the following steps</p>

						<ol>
							<li>Capture Frame from Input Stream</li>
							<li>Send Frame to WebGL</li>
							<li>Run AI Inference</li>
							<li>Post Processing</li>
							<li>Write Frame to Canvas</li>
							<li>Capture Frame from Input Stream</li>
						</ol>


						<p>The following table outlines what resources are being used by each step, and what that usage scales with:</p>


						<h5 >Selfie Model</h5>
						<div class="table-responsive my-4">
							<table class="table" style="border-color: white">

								<tbody >

								<tr style="text-align: center; font-weight: bold;" >
									<td style="border-top: white;"></td>
									<td style="border-top: white;">Uses CPU?</td>
									<td style="border-top: white;">Uses GPU?</td>
									<td style="border-top: white;">Scales with Resolution?</td>
									<td style="border-top: white;">Scales with Video FrameRate?</td>
									<td style="border-top: white;">Scales with Segmentation Frame Rate?</td>
								</tr>

								<tr style="text-align: center">
									<td style="border-top: white; text-align: left; ">1. Capture Frame from Input Stream</td>
									<td style="border-top: white;background:#ffeccf">Yes</td>
									<td style="border-top: white;background: #d3ffd8">No</td>
									<td style="border-top: white;background:#ffeccf">Yes</td>
									<td style="border-top: white;background:#ffeccf">Yes</td>
									<td style="border-top: white;background: #d3ffd8">No</td>
								</tr>
								<tr style="text-align: center">
									<td style="border-top: white; text-align: left; ">2. Send Frame to WebGL</td>
									<td style="border-top: white;background:#ffeccf">Yes</td>
									<td style="border-top: white;background:#ffeccf">Yes</td>
									<td style="border-top: white;background:#ffeccf">Yes</td>
									<td style="border-top: white;background:#ffeccf">Yes</td>
									<td style="border-top: white;background: #d3ffd8">No</td>
								</tr>

								<tr style="text-align: center">
									<td style="border-top: white; text-align: left; ">3. Run AI Inference</td>
									<td style="border-top: white;background:#ffeccf">Yes</td>
									<td style="border-top: white;background: #d3ffd8">No</td>
									<td style="border-top: white;background: #d3ffd8">No</td>
									<td style="border-top: white;background: #d3ffd8">No</td>
									<td style="border-top: white;background:#ffeccf">Yes</td>
								</tr>

								<tr style="text-align: center">
									<td style="border-top: white; text-align: left; ">4. Post Processing</td>
									<td style="border-top: white;background: #d3ffd8">No</td>
									<td style="border-top: white;background:#ffeccf">Yes</td>
									<td style="border-top: white;background: #d3ffd8">No</td>
									<td style="border-top: white;background:#ffeccf">Yes</td>
									<td style="border-top: white;background: #d3ffd8">No</td>
								</tr>

								<tr style="text-align: center">
									<td style="border-top: white; text-align: left; ">5. Write frame to Canvas</td>
									<td style="border-top: white;background:#ffeccf">Yes</td>
									<td style="border-top: white;background: #d3ffd8">No</td>
									<td style="border-top: white;background:#ffeccf">Yes</td>
									<td style="border-top: white;background:#ffeccf">Yes</td>
									<td style="border-top: white;background: #d3ffd8">No</td>
								</tr>

								<tr style="text-align: center">
									<td style="border-top: white; text-align: left; ">6. Get Output Stream</td>
									<td style="border-top: white;background:#ffeccf">Yes</td>
									<td style="border-top: white;background: #d3ffd8">No</td>
									<td style="border-top: white;background:#ffeccf">Yes</td>
									<td style="border-top: white;background:#ffeccf">Yes</td>
									<td style="border-top: white;background: #d3ffd8">No</td>
								</tr>
								</tbody>
							</table>
						</div>

						<h5 >WebGL Model</h5>
						<div class="table-responsive my-4">
							<table class="table" style="border-color: white">

								<tbody >

								<tr style="text-align: center; font-weight: bold;" >
									<td style="border-top: white;"></td>
									<td style="border-top: white;">Uses CPU?</td>
									<td style="border-top: white;">Uses GPU?</td>
									<td style="border-top: white;">Scales with Resolution?</td>
									<td style="border-top: white;">Scales with Video FrameRate?</td>
									<td style="border-top: white;">Scales with Segmentation Frame Rate?</td>
								</tr>

								<tr style="text-align: center">
									<td style="border-top: white; text-align: left; ">1. Capture Frame from Input Stream</td>
									<td style="border-top: white;background:#ffeccf">Yes</td>
									<td style="border-top: white;background: #d3ffd8">No</td>
									<td style="border-top: white;background:#ffeccf">Yes</td>
									<td style="border-top: white;background:#ffeccf">Yes</td>
									<td style="border-top: white;background: #d3ffd8">No</td>
								</tr>
								<tr style="text-align: center">
									<td style="border-top: white; text-align: left; ">2. Send Frame to WebGL</td>
									<td style="border-top: white;background:#ffeccf">Yes</td>
									<td style="border-top: white;background:#ffeccf">Yes</td>
									<td style="border-top: white;background:#ffeccf">Yes</td>
									<td style="border-top: white;background:#ffeccf">Yes</td>
									<td style="border-top: white;background: #d3ffd8">No</td>
								</tr>

								<tr style="text-align: center">
									<td style="border-top: white; text-align: left; ">3. Run AI Inference</td>
									<td style="border-top: white;background: #d3ffd8">No</td>
									<td style="border-top: white;background:#ffeccf">Yes</td>
									<td style="border-top: white;background: #d3ffd8">No</td>
									<td style="border-top: white;background: #d3ffd8">No</td>
									<td style="border-top: white;background:#ffeccf">Yes</td>
								</tr>

								<tr style="text-align: center">
									<td style="border-top: white; text-align: left; ">4. Post Processing</td>
									<td style="border-top: white;background: #d3ffd8">No</td>
									<td style="border-top: white;background:#ffeccf">Yes</td>
									<td style="border-top: white;background: #d3ffd8">No</td>
									<td style="border-top: white;background:#ffeccf">Yes</td>
									<td style="border-top: white;background: #d3ffd8">No</td>
								</tr>

								<tr style="text-align: center">
									<td style="border-top: white; text-align: left; ">5. Write frame to Canvas</td>
									<td style="border-top: white;background:#ffeccf">Yes</td>
									<td style="border-top: white;background: #d3ffd8">No</td>
									<td style="border-top: white;background:#ffeccf">Yes</td>
									<td style="border-top: white;background:#ffeccf">Yes</td>
									<td style="border-top: white;background: #d3ffd8">No</td>
								</tr>

								<tr style="text-align: center">
									<td style="border-top: white; text-align: left; ">6. Get Output Stream</td>
									<td style="border-top: white;background:#ffeccf">Yes</td>
									<td style="border-top: white;background: #d3ffd8">No</td>
									<td style="border-top: white;background:#ffeccf">Yes</td>
									<td style="border-top: white;background:#ffeccf">Yes</td>
									<td style="border-top: white;background: #d3ffd8">No</td>
								</tr>
								</tbody>
							</table>
						</div>

						<p>While for some larger / slower models like Bodypix, the AI Inference itself used a lot of resources, Vectorly's AI-model implementations are light enough that the main sources of resource-consumption are the overhead of sending data to the canvas (2) and using <code>canvas.captureStream()</code>(6)</p>

					</section><!--//section-->
				     <section class="docs-section" id="item-upscale-performance">

						 <h2 class="section-heading">AI Upscaling</h2>

						<p>The primary "cost" to doing super-resolution is computational complexity. While we have put a lot of work into making super resolution feasible on client devices, it is still something which needs to be managed. Here, we provide some initial performance benchmarks for the same demos shown above, in the demos sections.</p>

						 <figure class="figure docs-figure py-3">
							 <img class="figure-img img-fluid" src="assets/images/framerate-upscaling.svg" alt="" style="width: 800px;">
						 </figure>


						 <figure class="figure docs-figure py-3">
							 <img class="figure-img img-fluid" src="assets/images/cpu-usage-upscaling.svg" alt="" style="width: 800px;">
						 </figure>

						 <h4  id="item-upscale-performance-considerations">Performance Considerations</h4>

						 <p>AI Upscaling does require some computational effort, however it is mostly on the graphics card, so AI Upscaling's impact on CPU is limited. The amount of computation (and therefore the framerate / performance) depends on the size of input video you are upscaling</p>

						 <p>The following table should give a rough idea performance for different input video resolutions. These results are only for Web environments. Our mobile SDKs will have access to more powerful native libraries, enabling significantly better performance.</p>

						 <div class="table-responsive my-4">
							 <table class="table table-striped">

								 <tr>
									 <th scope="col"></th>
									 <th scope="col">240p -> 480p/720p</th>
									 <th scope="col">360p -> 720p/1080p</th>
									 <th scope="col">480p -> 960p/1440p</th>
								 </tr>

								 <tbody>


								 <tr>
									 <th scope="row">High End Smartphone</th>
									 <td>120 fps</td>
									 <td>40 fps</td>
									 <td>14fps</td>
								 </tr>

								 <tr>
									 <th scope="row">Mid-range Smartphone</th>

									 <td>80 fps</td>
									 <td>28 fps</td>
									 <td>9 fps</td>
								 </tr>

								 <tr>
									 <th scope="row">Low-End Smartphone</th>

									 <td>20fps</td>
									 <td>6fps</td>
									 <td>3fps</td>
								 </tr>

								 <tr>

									 <th scope="row">Mid-range Laptop</th>

									 <td>100fps</td>
									 <td>35fps</td>
									 <td>8fps</td>
								 </tr>

								 <tr>

									 <th scope="row">GPU Desktop</th>

									 <td>200+fps</td>
									 <td>200+fps</td>
									 <td>80 fps</td>
								 </tr>


								 </tbody>
							 </table>
						 </div>


						 <p>You can measure the fps on any given device by adding the <code>analyticsEnabled</code> flag as <code>true</code> in the configuration parameters.


						 <pre>
							 <code>
  const config = {
	   token: '...',
	   analyticsEnabled: true
   };

   const upscaler = new UpscaleFilter(video, config);
							 </code>
						 </pre>

						 </p>


						 <p>You can then measure the fps at any time with <code>upscaler.metrics.fps</code> property. The fps number provided by <code>upscaler.metrics.fps</code> will not exceed the source video's frame rate because we only render when a video frame changes. </p>

						 <p>
							 It's recommended to stick to 240p or 360p inputs, as mid-range devices tend to struggle with larger inputs. You can also <a href="#item-upscale-controls">disable upscaling</a>  if the fps gets too low.</p>


						<h4 >Quality</h4>
						<p>The primary benefit of Super resolution is to increase video quality. Using the original high-resolution video as a reference, we can use traditional video quality metrics like VMAF to quantify the quality improvement of Super Resolution, when compared to normal bicubic upscaling of the downsampled / low-resolution video content.</p>


						<figure class="figure docs-figure py-3">
							<img class="figure-img img-fluid" src="assets/images/quality-comparison.svg" alt="" style="width: 800px;">
						</figure>


						<p>Our general AI upscaler filter generally achieves a 10 to 15 point VMAF improvement compared to bicubic scaling. With <a href="#item-upscale-models"> content-specific AI models</a>, or heavier models, we will likely be able to achieve further quality gains. We are currently working on releasing quality comparisons for content specific models.</p>


						<h5>Quality visualization</h5>

						<p>For reference, below are side by side comparisons of bicubic upscaling of the low-resolution original / Super resolution of the low-resolution / High resolution original </p>

						<p style="text-decoration: underline">Jellyfish</p>
						<figure class="figure docs-figure py-3">

							<div class="table-responsive my-4">
								<table class="table" style="border-color: white">

									<tbody >
									<tr>

										<td style="border-top: white;"><img class="figure-img img-fluid" src="assets/images/jellyfish-240p.png" alt="" style="height: 250px;"></td>
										<td style="border-top: white;"><img class="figure-img img-fluid" src="assets/images/jellyfish-upscaled.png" alt="" style="height: 250px;"></td>
										<td style="border-top: white;"><img class="figure-img img-fluid" src="assets/images/jellyfish-720p.png" alt="" style="height: 250px;"></td>
									</tr>
									<tr style="text-align: center">
										<td style="border-top: white;"><figcaption class="figure-caption mt-3">Bicubic (240p)</figcaption></td>
										<td style="border-top: white;"><figcaption class="figure-caption mt-3">240p upscaled to 720p</figcaption></td>
										<td style="border-top: white;"><figcaption class="figure-caption mt-3">Original 720p</figcaption></td>
									</tr>
									</tbody>
								</table>
							</div>

						</figure>

						<p style="text-decoration: underline">Ducks</p>
						<figure class="figure docs-figure py-3">

							<div class="table-responsive my-4">
								<table class="table" style="border-color: white">

									<tbody >
									<tr>

										<td style="border-top: white;"><img class="figure-img img-fluid" src="assets/images/ducks-240p.png" alt="" style="height: 250px;"></td>
										<td style="border-top: white;"><img class="figure-img img-fluid" src="assets/images/ducks-upscaled.png" alt="" style="height: 250px;"></td>
										<td style="border-top: white;"><img class="figure-img img-fluid" src="assets/images/ducks-720p.png" alt="" style="height: 250px;"></td>
									</tr>
									<tr style="text-align: center">
										<td style="border-top: white;"><figcaption class="figure-caption mt-3">Bicubic (240p)</figcaption></td>
										<td style="border-top: white;"><figcaption class="figure-caption mt-3">240p upscaled to 720p</figcaption></td>
										<td style="border-top: white;"><figcaption class="figure-caption mt-3">Original 720p</figcaption></td>
									</tr>
									</tbody>
								</table>
							</div>

						</figure>


						<p style="text-decoration: underline;">Tractor</p>
						<figure class="figure docs-figure py-3">

							<div class="table-responsive my-4">
								<table class="table" style="border-color: white">

									<tbody >
									<tr>

										<td style="border-top: white;"><img class="figure-img img-fluid" src="assets/images/tractor-240p.png" alt="" style="height: 250px;"></td>
										<td style="border-top: white;"><img class="figure-img img-fluid" src="assets/images/tractor-upscaled.png" alt="" style="height: 250px;"></td>
										<td style="border-top: white;"><img class="figure-img img-fluid" src="assets/images/tractor-720p.png" alt="" style="height: 250px;"></td>
									</tr>
									<tr style="text-align: center">
										<td style="border-top: white;"><figcaption class="figure-caption mt-3">Bicubic (240p)</figcaption></td>
										<td style="border-top: white;"><figcaption class="figure-caption mt-3">240p upscaled to 720p</figcaption></td>
										<td style="border-top: white;"><figcaption class="figure-caption mt-3">Original 720p</figcaption></td>
									</tr>
									</tbody>
								</table>
							</div>

						</figure>

					</section><!--//section-->

			    </article><!--//docs-article-->


			    <footer class="footer">
				    <div class="container text-center py-5">

				        <ul class="social-list list-unstyled pt-4 mb-0">
							<li class="list-inline-item"><a href="https://github.com/Vectorly"><i class="fab fa-github fa-fw"></i></a></li>
							<li class="list-inline-item"><a href="https://www.linkedin.com/company/vectorly"><i class="fab fa-linkedin fa-fw"></i></a></li>
							<li class="list-inline-item"><a href="https://angel.co/vectorly"><i class="fab fa-angellist fa-fw"></i></a></li>
				        </ul><!--//social-list-->
				    </div>
			    </footer>
		    </div>
	    </div>
    </div><!--//docs-wrapper-->



    <!-- Javascript -->
    <script src="assets/plugins/jquery-3.4.1.min.js"></script>
    <script src="assets/plugins/popper.min.js"></script>
    <script src="assets/plugins/bootstrap/js/bootstrap.min.js"></script>


    <!-- Page Specific JS -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.8/highlight.min.js"></script>
    <script src="assets/js/highlight-custom.js"></script>
    <script src="assets/plugins/jquery.scrollTo.min.js"></script>
    <script src="assets/plugins/lightbox/dist/ekko-lightbox.min.js"></script>
    <script src="assets/js/docs.js"></script>




    <script type="text/javascript">
        window._mfq = window._mfq || [];
        (function() {
            var mf = document.createElement("script");
            mf.type = "text/javascript"; mf.defer = true;
            mf.src = "//cdn.mouseflow.com/projects/ade379db-9c1a-4bba-9bf0-a0fbf6ceb01e.js";
            document.getElementsByTagName("head")[0].appendChild(mf);
        })();
    </script>

</body>
</html>

