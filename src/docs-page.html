<!DOCTYPE html>
<html lang="en">
<head>
    <title>Vectorly: AI Filters Documentation</title>
    <!-- Meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
	<meta content="Vectorly: AI Filters Documentation" property="og:title">
	<meta
			content="Vectorly's SDK makes it easy to deploy AP Filters into WebRTC and video streaming applications"
			name="description">
	<meta content="https://vectorly.io/images/new/ai-compression-temporary.png" property="og:image">

	<meta content="Vectorly: Realtime AI Filters" property="twitter:title">
	<meta
			content="Vectorly's SDK makes it easy to deploy AP Filters into WebRTC and video streaming applications"
			property="twitter:description">
	<meta content="https://vectorly.io/images/new/ai-compression-temporary.png" property="twitter:image">

    <meta name="author" content="Vectorly">

	<meta property="og:type" content="website">
	<meta content="summary_large_image" name="twitter:card">

    <link rel="shortcut icon" href="assets/images/vectorly-logo-circle.svg">

    <!-- Google Font -->
    <link href="https://fonts.googleapis.com/css?family=Poppins:300,400,500,600,700&display=swap" rel="stylesheet">

    <!-- FontAwesome JS-->
    <script defer src="assets/fontawesome/js/all.min.js"></script>

    <!-- Plugins CSS -->
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.2/styles/atom-one-dark.min.css">

    <!-- Theme CSS -->
    <link id="theme-style" rel="stylesheet" href="assets/css/theme.css">


	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=UA-134514531-1"></script>
	<script>
		window.dataLayer = window.dataLayer || [];
		function gtag(){dataLayer.push(arguments);}
		gtag('js', new Date());

		gtag('config', 'UA-134514531-1');
	</script>

</head>

<body class="docs-page">
    <header class="header fixed-top">
        <div class="branding docs-branding">
            <div class="container-fluid position-relative py-2">
                <div class="docs-logo-wrapper">
					<button id="docs-sidebar-toggler" class="docs-sidebar-toggler docs-sidebar-visible mr-2 d-xl-none" type="button">
	                    <span></span>
	                    <span></span>
	                    <span></span>
	                </button>
	                <div class="site-logo"><a class="navbar-brand" href="index.html"><img class="logo-icon mr-2" src="assets/images/vectorly-logo-circle.svg" alt="logo"><span class="logo-text">Vectorly<span class="text-alt">&nbsp;Docs</span></span></a></div>
                </div><!--//docs-logo-wrapper-->
	            <div class="docs-top-utilities d-flex justify-content-end align-items-center">

					<ul class="social-list list-inline mx-md-3 mx-lg-5 mb-0 d-none d-lg-flex">
						<li class="list-inline-item"><a href="https://github.com/Vectorly"><i class="fab fa-github fa-fw"></i></a></li>
			            <li class="list-inline-item"><a href="https://www.linkedin.com/company/vectorly"><i class="fab fa-linkedin fa-fw"></i></a></li>
		                <li class="list-inline-item"><a href="https://angel.co/vectorly"><i class="fab fa-angellist fa-fw"></i></a></li>
		            </ul><!--//social-list-->
		            <a href="https://upscaler.vectorly.io/#/signup" class="btn btn-primary d-none d-lg-flex">Sign up</a>
					<a href="mailto:team@vectorly.io" class="btn btn-outline-primary d-none d-lg-flex" style="margin-left: 20px;">Contact</a>
	            </div><!--//docs-top-utilities-->
            </div><!--//container-->
        </div><!--//branding-->
    </header><!--//header-->

    <div class="docs-wrapper">
	    <div id="docs-sidebar" class="docs-sidebar">
		    <div class="top-search-box d-lg-none p-3">
                <form class="search-form">
		            <input type="text" placeholder="Search the docs..." name="search" class="form-control search-input">
		            <button type="submit" class="btn search-btn" value="Search"><i class="fas fa-search"></i></button>
		        </form>
            </div>
		    <nav id="docs-nav" class="docs-nav navbar">
			    <ul class="section-items list-unstyled nav flex-column pb-3">
				    <li class="nav-item section-title"><a class="nav-link scrollto active" href="#section-intro"><span class="theme-icon-holder mr-2"><i class="fas fa-map-signs"></i></span>Introduction</a></li>
				    <li class="nav-item"><a class="nav-link scrollto" href="#item-installation">Installation</a></li>
				    <li class="nav-item"><a class="nav-link scrollto" href="#item-available-filters">Available Filters</a></li>
				    <li class="nav-item section-title mt-3"><a class="nav-link scrollto" href="#section-background"><span class="theme-icon-holder mr-2"><i class="fas fa-file-code"></i></span>Background Filters</a></li>
					<li class="nav-item"><a class="nav-link scrollto" href="#item-background-loading">Loading</a></li>
					<li class="nav-item"><a class="nav-link scrollto" href="#item-background-basic-usage">Basic Usage</a></li>
					<li class="nav-item"><a class="nav-link scrollto" href="#item-background-integration">Integration</a></li>
					<li class="nav-item"><a class="nav-link scrollto" href="#item-background-events">Events</a></li>
					<li class="nav-item"><a class="nav-link scrollto" href="#item-background-controls">Controls</a></li>

				    <li class="nav-item section-title mt-3"><a class="nav-link scrollto" href="#section-upscaling"><span class="theme-icon-holder mr-2"><i class="fas fa-laptop-code"></i></span>AI Upscaling</a></li>
					<li class="nav-item"><a class="nav-link scrollto" href="#item-upscale-loading">Loading</a></li>
				    <li class="nav-item"><a class="nav-link scrollto" href="#item-upscale-usage">Basic usage</a></li>
				    <li class="nav-item"><a class="nav-link scrollto" href="#item-upscale-integration">Integration</a></li>
					<li class="nav-item"><a class="nav-link scrollto" href="#item-upscale-ott">HTML5 Players</a></li>
				    <li class="nav-item"><a class="nav-link scrollto" href="#item-upscale-events">Events</a></li>
					<li class="nav-item"><a class="nav-link scrollto" href="#item-upscale-controls">Controls</a></li>
					<li class="nav-item"><a class="nav-link scrollto" href="#item-upscale-styling">Styling and Scaling</a></li>
					<li class="nav-item"><a class="nav-link scrollto" href="#item-upscale-models">AI Models</a></li>
					<li class="nav-item"><a class="nav-link scrollto" href="#item-upscale-low-level">Low level controls</a></li>
					<li class="nav-item"><a class="nav-link scrollto" href="#item-upscale-mobile">Mobile</a></li>
				    <li class="nav-item section-title mt-3"><a class="nav-link scrollto" href="#section-demos"><span class="theme-icon-holder mr-2"><i class="fas fa-file-video"></i></span>Demos</a></li>
				    <li class="nav-item section-title mt-3"><a class="nav-link scrollto" href="#section-performance"><span class="theme-icon-holder mr-2"><i class="fas fa-chart-bar"></i></span>Performance</a></li>
					<li class="nav-item"><a class="nav-link scrollto" href="#item-background-performance">Background</a></li>
					<li class="nav-item"><a class="nav-link scrollto" href="#item-upscale-performance">Upscaling</a></li>
			    </ul>

		    </nav><!--//docs-nav-->
	    </div><!--//docs-sidebar-->
	    <div class="docs-content">
		    <div class="container">
			    <article class="docs-article" id="section-intro">
				    <header class="docs-header">
					    <h1 class="docs-heading">Introduction <span class="docs-time">Last updated: 2021-06-11</span></h1>
					    <section class="docs-intro" >
							<p>Vectorly's client-side SDK makes it easy to integrate AI filters, such as Background Filters (virtual backgrounds, background blur) as well as AI Upscaling, into WebRTC streaming applications</p>
						</section><!--//docs-intro-->



						<section class="docs-section" id="item-installation">
							<h2 class="section-heading">Installation</h2>




							<p>When you <a href="https://upscaler.vectorly.io" target="_blank"> sign up</a>, you'll get a <code>token</code> which, you will need to use the library. Next, you can install the ai-filters library via NPM or via CDN</p>


							<p> <b>NPM</b>
								<code><pre>npm -i @vectorly/ai-filters</pre></code>
							</p>

							<p><b>CDN</b>
								<code><pre>https://cdn.vectorly.io/v2/latest/ai-filters.js</pre></code></p>
						</section>


						<section class="docs-section" id="item-available-filters">
							<h2 class="section-heading">Available Filters</h2>
							<p>We've compiled a set of AI filters from research & Academia, open source projects as well as our own custom AI filters, all of which are able to be accessed through the same Vectorly interface.</p>
							<h4>Background Filter</h4>



							<p>By using the Background Filter, you can implement features like Virtual Backgrounds or Background Blur, to give users additional privacy when calling from home. The AI model used for running background segmentation is the <code>meet</code> model, used by Google Meet.</p>

							<div style="text-decoration: underline">Background Filters example:</div>
							<figure class="figure docs-figure py-3">


								<div class="table-responsive my-4">
									<table class="table" style="border-color: white">

										<tbody >
										<tr>

											<td style="border-top: white;"><img class="figure-img img-fluid" src="assets/images/videocall-original.png" alt="" style="width: 320px;"></td>
											<td style="border-top: white;"><img class="figure-img img-fluid" src="assets/images/background-blur.png" alt="" style="width: 320px;"></td>
											<td style="border-top: white;"><img class="figure-img img-fluid" src="assets/images/virtual-background.png" alt="" style="width: 320px;"></td>
										</tr>
										<tr style="text-align: center">
											<td style="border-top: white;"><figcaption class="figure-caption mt-3">Original Video Stream</figcaption></td>
											<td style="border-top: white;"><figcaption class="figure-caption mt-3">Background Blur</figcaption></td>
											<td style="border-top: white;"><figcaption class="figure-caption mt-3">Virtual Background</figcaption></td>
										</tr>
										</tbody>
									</table>
								</div>

							</figure>

							<p>See the <a href="#section-background"> Background Filters section</a> for more details</p>


							<h4>Upscaling Filter</h4>
							<p>Vectorly has built it's own AI Upscaling filter based on a technique called <a href="https://en.wikipedia.org/wiki/Super-resolution_imaging">Super Resolution</a>, which uses AI to upscale and enhance images. Through Super Resolution, we can upscale and clean-up low-resolution video, making it look close to HD quality.</p>


							<div style="text-decoration: underline">Super Resolution Example:</div>
							<figure class="figure docs-figure py-3">

								<div class="table-responsive my-4">
									<table class="table" style="border-color: white">

										<tbody >
										<tr>

											<td style="border-top: white;"><img class="figure-img img-fluid" src="assets/images/ducks-240p.png" alt="" style="height: 250px;"></td>
											<td style="border-top: white;"><img class="figure-img img-fluid" src="assets/images/ducks-upscaled.png" alt="" style="height: 250px;"></td>
											<td style="border-top: white;"><img class="figure-img img-fluid" src="assets/images/ducks-720p.png" alt="" style="height: 250px;"></td>
										</tr>
										<tr style="text-align: center">
											<td style="border-top: white;"><figcaption class="figure-caption mt-3">240p</figcaption></td>
											<td style="border-top: white;"><figcaption class="figure-caption mt-3">240p upscaled to 720p</figcaption></td>
											<td style="border-top: white;"><figcaption class="figure-caption mt-3">Original 720p</figcaption></td>
										</tr>
										</tbody>
									</table>
								</div>

							</figure>

							<p>With AI Upscaling, you can improve the clarity & quality of video streams when the source resolution is of low quality.
							</p>

							<figure class="figure docs-figure py-3">
								<img class="figure-img img-fluid" src="assets/images/ai-compression.svg" alt="" style="width: 800px;">
								<!--<figcaption class="figure-caption mt-3"><i class="fas fa-info-circle mr-2"></i>Credit: the above screencast is taken from .</figcaption> -->
							</figure>


								<p>You can also stream SD content to users and upscale it to HD in real time as they're watching it, providing an HD viewing experience while only consuming the bandwidth for the low-resolution video (50 to 90% less data than for the HD video).</p>
							<p>See the <a href="#section-upscaling"> AI Upscaling section</a> for more details</p>


							<h4>Audio Denoise</h4>


							<p>In Development</p>
							<h4>Video Denoise</h4>

							<p>In Development</p>

							<h4>Lighting Correction</h4>

							<p>In Development</p>


						</section><!--//section-->


				    </header>


			    </article>

			    <article class="docs-article" id="section-background">

					<h1 class="docs-heading">Background Filters</h1>



						<h4 class="section-heading"  id="item-background-loading">Loading</h4>

						<p>The basic API for loading the background filter via NPM is:
							<code><pre>

     import BackgroundFilter from @vectorly-io/ai-filters;
					</pre></code>

						</p>


						<p>For loading via CDN, you can access the background filter from the <code>vectorly</code> object


							<code><pre>

     const BackgroundFilter = vectorly.BackgroundFilter;
					</pre></code>

					<section class="docs-section"  id="item-background-basic-usage">

						<h4 class="section-heading">Basic Usage</h4>

						<p>Vectorly's Background Filter takes as an input any  <code>MediaStream</code>  or <code>MediaStreamTrack</code> element, so for a WebRTC application, all you need to do is to instantiate the filter object with the  <code>MediaStream</code> or <code>MediaStreamTrack</code>  element you want to filter. The output is a <code>MediaStreamTrack</code>, which can be sent via WebRTC or loaded locally into a <code>video</code> element</p>




						<p>The basic API for loading the background filter is:

							<code><pre>

   const stream = await navigator.mediaDevices.getUserMedia({video:true, audio:true});
   const filter = new BackgroundFilter(stream, {token: 'vectorly-token', {type: 'blur'});
   const outputStream =  filter.getOutput();
					</pre></code>
						</p>


						<p>The above example is for a Background Blur filter. For virtual backgrounds, where you replace the background with an image, the API is:

							<code><pre>

   const filter = new BackgroundFilter(stream, {token: 'vectorly-token', {type: 'virtual', 'image': 'my-image-url.png'});
					</pre></code>
						</p>





					</section>

					<section class="docs-section" id="item-background-integration">
						<h2 class="section-heading">Integration</h2>

						<p>
							Integrating the filter with any specific Video Conferencing API or service just requires finding the <code>MediaStream</code> element associated with video stream you want to filter. The following sub-sections discuss how to integrate the filter with various conferencing services.
						</p>




						<p><b>Vanilla WebRTC</b></p>
						<p>As shown above, the API for basic/general WebRTC is:</p>


						<pre><code>
   navigator.mediaDevices.getUserMedia({video:true, audio:true}).then(function(stream) {

      const filter = new BackgroundFilter(stream, {token: 'insert-vectorly-token-here', type: 'blur'});
      const outputStream =  filter.getOutput();  //Video Stream Track
   });

</code></pre>

						<p>You can find a demo repository for vanilla WebRTC background filtering <a href="https://files.vectorly.io/demo/background/webrtc/index.html">here</a></p>



						<p><b>Jitsi</b></p>

						<p>You can enable filters on any <code>VideoTrack</code> object by feeding into the Filter's Jitsi Plugin (see <a href="https://jitsi.github.io/handbook/docs/dev-guide/dev-guide-ljm-api#jitsitrack">reference</a>).


						<pre><code>
   const room = connection.initJitsiConference('conference', confOptions);

   JitsiMeetJS.createLocalTracks({devices: ['video']}).then(tracks => {
      const filter = new BackgroundFilter(tracks[0], {token: 'insert-vectorly-token', type: 'blur'});
      room.addTrack(filter.getOutput());
   });


</code></pre>



						<p><b>Agora</b></p>


						<p>For Web deployments using <a href="https://www.agora.io">Agora</a> (specifically the 4.x API), you can just feed the video track to the Background filter, which will return a filtered video track which you can publish.</p>

						<p>
						<pre><code>
    let videoTrack = AgoraRTC.createCameraVideoTrack();
    let audioTrack = AgoraRTC.createMicrophoneAudioTrack();


    const filter = new BackgroundFilter(videoTrack, {token: 'insert-vectorly-token-here', type: 'blur'});
    const filteredTrack = filter.getOutput();
    client.publish([filtedredTrack, audioTrack], handleFail);
						</code></pre>
						</p>



						<p><b>Twilio</b></p>

						<p>You can enable filters on any <code>VideoTrack</code> object by feeding it to the Twilio plugin (see <a href="https://media.twiliocdn.com/sdk/js/video/releases/2.13.1/docs/VideoTrack.html#attach">reference</a>).


						<pre><code>
   const Video = require('twilio-video');

   Video.createLocalVideoTrack().then(function(videoTrack) {
     const filter = new BackgroundFilter(videoTrack, {token: 'insert-vectorly-token', type: 'blur'});
	 const filteredTrack = filter.getOutput();
	//publish filteredTrack
   });
							</code></pre>





						<p><b>Vonage / OpenTok</b></p>

						<p>When you create a <code>Publisher</code> object, just feed that to the OpenTok plugin.


						<pre><code>
   var publisher = OT.initPublisher('publisher', {
      insertMode: 'append',
      width: '100%',
      height: '100%'
   }, handleError);

   const filter = new BackgroundFilter(publisher.getVideoSource(), {token: 'insert-vectorly-token', type: 'blur'});
   publisher.setVideoSource(filter.getOutput());
							</code></pre>

					</section><!--//section-->


					<h2 class="section-heading" id="item-background-events">Events</h2>


					<p>Once you have instantiated the filter object, you can access basic filter events, like onload and error handling.</p>

					<pre>
							 <code>
   const filter = new BackgroundFilter(stream, config);

   filter.on('load', function () {
     console.log("filter initialized");
   });

   filter.on('start', function () {
      console.log("Starting filter");
   });

   filter.on('stop', function () {
      console.log("Stopping filter");
   });

   filter.on('error', function () {
     console.log("Filter failed to initialize");
   });
							 </code>
						 </pre>

					<p>If the filter fails to load, then it will pass through the original video stream</p>


					<h2 class="section-heading" id="item-background-controls">Controls </h2>

					<p> You can also enable and disable the filter programatically.</p>

					<pre>
							 <code>
   const filter = new BackgroundFilter(video, config);

   filter.disable();

   filter.enable();
							 </code>
						 </pre>


			    </article><!--//docs-article-->


			    <article class="docs-article" id="section-upscaling">
				    <header class="docs-header">
					    <h1 class="docs-heading">AI Upscaling</h1>

						<h4 class="section-heading"  id="item-upscale-loading">Loading</h4>

						<p>The basic API for loading the background filter via NPM is:
							<code><pre>

     import vectorlyUpscaler from @vectorly-io/ai-upscaler;
					</pre></code>

						</p>


						<p>For loading via CDN, you can access the upscaling filter as the <code>vectorlyUpscaler</code> object, which will be available in the global scope





						    <p>For web environments, we've packaged our upscaler as a standalone Javascript library, as well as as plugins to several popular HTML5 video players (see the <a href="https://cdn.vectorly.io/upscaler/docs/latest/">full API</a> for more detail).</p>
					</header>

						<h4 class="section-heading" id="item-upscale-usage">Basic usage</h4>


						 <p>For the <code>vectorlyUpscaler</code>, the basic API involves instantiating an <code>vectorlyUpscaler</code> object, and specifying a <code>video</code> element.</p>



						 <pre>
							 <code>
   const video = document.getElementById("video");

   const config = {
	   token: '...'
   };

   const upscaler = new vectorlyUpscaler(video, config);
							 </code>
						 </pre>


						 <p>This automatically upscales the video, by overlaying a <code>canvas</code> element with the upscaled video frames on top of the <code>video</code> element. When the <code>video</code> plays, the upscaler will automatically upscale each frame and update the <code>canvas</code> element. See the <a href="#item-upscale-styling"> styling</a> section for more detail.</p>




					<section class="docs-section" id="item-upscale-integration">


						<h4 class="section-heading">Integration</h4>

						<p ><b>General WebRTC</b></p>


							<p>The <code>vectorlyUpscaler</code> works with any video tag, so for a WebRTC application, all you need to do is to instantiate the upscaler object with the <code>video</code> element you want to upscale.</p>


							<pre><code>
   const upscaler  = new vectorlyUpscaler(document.getElementById("remoteVideo"), {token: 'insert-vectorly-token-here'});

</code></pre>

							<p>We have an <a href="https://github.com/Vectorly/webrtc-demo"> example repository</a>, showing how Vectorly can be integrated with WebRTC, as well as a full working general WebRTC demo <a href="https://files.vectorly.io/demo/webrtc/index.html">here.</a> </p>


							<p>
								Integrating the upscaler with any specific Video Conferencing API or service just requires finding the video element associated with video stream you want to upscale.
							</p>


						<p ><b>Jitsi</b></p>

							<p>You can enable upscaling on any <code>VideoTrack</code> object by intercepting the corresponding <code>video</code> element you attach it to (see <a href="https://jitsi.github.io/handbook/docs/dev-guide/dev-guide-ljm-api#jitsitrack">reference</a>).


							<pre><code>
   const room = connection.initJitsiConference('conference', confOptions);
   room.on(JitsiMeetJS.events.conference.TRACK_ADDED, function(track){

      const videoElement = document.createElement('video');
      document.body.appendChild(videoElement);
      track.attach(videoElement);

      const upscaler = new vectorlyUpscaler(videoElement.current, {token: 'insert-vectorly-token'});

   });
</code></pre>


						<p ><b>Agora</b></p>


							<p>For Web deployments using <a href="https://www.agora.io">Agora</a>, you can find the <code>video</code> element of the stream you want to upscale by using the stream's ID.</p>

							<p>
							<pre><code>
    let stream = AgoraRTC.createStream({
        streamID: uid,
        audio: true,
        video: true,
        screen: false
    });

    stream.init(function() {

        stream.play('target-div');
        const video = document.getElementById("video" + stream.getId());
        const upscaler = new vectorlyUpscaler(video, {token: 'insert-vectorly-token-here'});

        client.publish(stream, handleFail);

    },handleFail);
						</code></pre>
							</p>


						<p ><b>Twilio</b></p>

							<p>You can enable upscaling on any <code>VideoTrack</code> object by intercepting the corresponding <code>video</code> element you attach it to (see <a href="https://media.twiliocdn.com/sdk/js/video/releases/2.13.1/docs/VideoTrack.html#attach">reference</a>).



							<p>If you use the <code>track.attach()</code> method to create a <code>video</code> element:</p>


							<pre><code>
   const Video = require('twilio-video');

   Video.createLocalVideoTrack().then(function(videoTrack) {
     const videoElement = videoTrack.attach();
     document.body.appendChild(videoElement);
     const upscaler = new vectorlyUpscaler(videoElement.current, {token: 'insert-vectorly-token'});
   });
							</code></pre>



							<p>If you specify your own <code>video</code> element:</p>


							<pre><code>
   const Video = require('twilio-video');

   const videoElement = document.createElement('video');
   document.body.appendChild(videoElement);

   Video.createLocalVideoTrack().then(function(videoTrack) {
     videoTrack.attach(videoElement);
     const upscaler = new vectorlyUpscaler(videoEl.current, {token: 'insert-vectorly-token'});
   });
							</code></pre>



						<p ><b>OpenTok / Vonage</b></p>

							<p>When a <code>Subscriber</code> or <code>Publisher</code> creates a <code>video</code> element you can intercept it and feed that video to the Vectorly Upscaler.



							<p>You can use the <code>subscriber.element</code> property to intercept the video element</p>


							<pre><code>
    session.on('streamCreated', function(event) {

        const subscriber = session.subscribe(event.stream, 'subscriber', {
            insertMode: 'append',
            width: '100%',
            height: '100%'
        }, handleError);

        subscriber.on('videoElementCreated', function (){
            const video = subscriber.element.querySelector('video');
            const upscaler  = new vectorlyUpscaler(video, {token: '..your-token....'});

        });

    });
							</code></pre>


							<p>This also works with a publisher object. Refer to the <a href="https://tokbox.com/developer/guides/customize-ui/js/">Vonage documentation</a>  for styling - Vectorly's upscaler will fit within the styling defined by OpenTok.</p>

							<p>See our example repistory for a <a href="https://github.com/Vectorly/ai-upscaler-examples/tree/master/vonage-demo"> working code example </a></p>

						<p ><b>Daily.co</b></p>
							<p>You can integrate Vectorly's AI upscaler with <a href="daily.co">Daily.co</a> if you're building a custom <a href="https://docs.daily.co/docs/build-a-custom-video-chat-interface">custom video chat interface </a>. Using the default React code sample from Daily, we've built a full working <a href="https://github.com/Vectorly/daily-call-object/">demo reference</a> </p>


							<pre><code>
   useEffect(() => {
	videoEl.current &&
	(videoEl.current.srcObject = new MediaStream([videoTrack]));
	if (videoEl.current && props.isLarge) {
	window.upscalers = window.upscalers || {}
	window.upscalers[videoTrack.id] = new vectorlyUpscaler(videoEl.current, {token: 'insert-vectorly-token'});
	}
   }, [videoTrack]);
							</code></pre>

							<p>You just need to make sure you intercept the <code>video</code> element associated with the video track you want to upscale.</p>

							<p>Vectorly's AI upscaler is not compatible with the pre-built UI from Daily.co, as the pre-built UI is loaded via iframe, making it impossible to access the <code>video</code> element through a third party application.</p>


						<p><b>Electron</b></p>


						<p>If you're building an electron app, the Vectorly library is fairly plug and play, and will work with either CDN or NPM installation. </p>

						<p>You can see a demo electron app repostory <a href="https://github.com/Vectorly/vectorly-electron-demo">here</a></p>




					</section>

						<h4 class="section-heading" id="item-upscale-ott">Plugins</h4>
						Besides the <code>vectorlyUpscaler</code> module, we have several plugins for specific HTML5 players. (see the <a href="https://cdn.vectorly.io/upscaler/docs/latest/">full API</a> for more detail).


						<p>

						<h4>VideoJS</h4>
						<pre>
							 <code>
   const player = videojs('my-video')
   videojs.registerPlugin('vectorlyPlugin', vectorlyUpscaler.videoJSPlugin);
   const vjsUpscaler = player.vectorlyPlugin({token: '...'})
							 </code>
						 </pre>

						</p>





						<p>

						<h4>Shaka player</h4>
						<pre>
							 <code>
    async function init() {
       const video = document.getElementById('my-video');
       const ui = video['ui'];
       const controls = ui.getControls();
       const player = controls.getPlayer();

       try {
           await player.load(url);
           // This runs if the asynchronous load is successful.
           const upscaler = new vectorlyUpscaler.shakaPlugin(player,{
                token: '...'
              });
       } catch (error) {
          console.log(error);
       }
    }

    document.addEventListener('shaka-ui-loaded', init);
							 </code>
						 </pre>

						</p>



					<h4>Custom plugin</h4>

					You can easily build a plugin for Vectorly for any HTML5 video player. All you really need is the <code>video</code> tag, and the video container <code>div</code>, which contains the video UI elements and which is used for <a href="#item-upscale-styling">styling and layout</a>. See a demo plugin code, off of which our other HMTL5 Player plugins are based
					<pre>
							 <code>
   import vectorlyUpscaler from '@vectorly-io/ai-upscaler';

   class myPlugin {

     constructor(videoElement, config){

       const container = videoElement.parentNode; // Or whatever the video container div is
       const upscaler = new vectorlyUpscaler(videoElement, config);
       this.upscaler = upscaler;

     }

     on(event, callback){
       this.upscaler.on(event, callback)
     }

     enable(){
       this.upscaler.enable();
     }

     disable(){
       this.upscaler.disable();
     }

     changeNetwork(networkParams) {
         this.upscaler.changeNetwork(networkParams)
     }
   }

   export default myPlugin
							 </code>
						 </pre>

					</p>



						<h2 class="section-heading" id="item-upscale-events">Events</h2>


						<p>Once you have instantiated the upscaler object, you can access basic upscaler events, like onload and error handling.</p>

						<pre>
							 <code>
   const upscaler = new vectorlyUpscaler(video, config);

   upscaler.on('load', function () {
     console.log("Upscaler initialized");
   });

   upscaler.on('start', function () {
      console.log("Starting upscaling");
   });

   upscaler.on('stop', function () {
      console.log("Stopping upscaling");
   });

   upscaler.on('error', function () {
     console.log("Failed to initialize");
   });
							 </code>
						 </pre>


						<h2 class="section-heading" id="item-upscale-controls">Controls </h2>

						<p> You can also enable and disable the upscaler programatically.</p>

						<pre>
							 <code>
   const upscaler = new vectorlyUpscaler(video, config);

   upscaler.disable();

   upscaler.enable();
							 </code>
						 </pre>




						<h2 class="section-heading" id="item-upscale-styling">Styling and Scaling</h2>

						<p>

							Let's say you have a video element, inside of a basic container div.

							<code><pre>

   &lt;div id=&quot;container&quot;&gt;
      &lt;video src="video.mp4" &gt;&lt;/video&gt;
   &lt;/div&gt;
				</pre></code>
</p>


					<p>
					When you feed that  <code>video</code> element to the Upcaler instantiation function, it will create a <code>canvas</code> element as a sibling node, with the same parent node as the <code>video</code> element.

						<code><pre>

     &lt;div id=&quot;container&quot;&gt;
         &lt;video src=&quot;video.mp4&quot;  style=&quot;visibility: hidden&quot;&gt;&lt;/video&gt;
         &lt;canvas  id=&quot;output&quot; &gt;&lt;/canvas&gt;  // Where the upscaled frames are drawn
      &lt;/div&gt;
				</pre></code>
					The upscaler library styles this canvas to occupy 100% of the width and height of the parent element, which in practice, covers the video element in most HTML5 video player interfaces.

					</p>

					<p>
							To have more control over the styling and position of the output, you can use the <code>container</code>option, to specify a div element to place the destination canvas.
							<code>
								<pre>


   const video = document.getElementById("video");
   const div = document.getElementById("my-div");

   const config = {
	   token: '...',
	   container:  div //Any div element,
   };

   const upscaler = new vectorlyUpscaler(video, config);
				</pre></code>

					The output canvas will occupy the exact dimensions of the container div, and will dynamically resize and re-position whenever the container div is moved, resized or changed. To dynamically style and position the output therefore, you should style and position the container element.
						</p>






						<h2 class="section-heading" id="item-upscale-models">Models</h2>

						<p>There are multiple AI models you can choose from. The default is 'residual_3k_3x', but you can specify a model when instantiating the upscaler object
						<pre><code>
   const upscaler = new vectorlyUpscaler(video, {token: '...', networkParams: { name: 'residual_3k_3x', tag: 'general', version: '2.1'}});
							 </code></pre>
						We are constantly releasing new models. You can find a comprehensive list of models <a href="https://cdn.vectorly.io/upscaler/docs/latest/global.html#NetworkParams" >here</a>




					<br></br>


					<h2 class="section-heading" id="item-upscale-low-level">Low level controls</h2>

					<p>For use cases where lower level control is needed, such as upscaling indidual frames or images, using a custom decoder or upscaling as part of a broader image processing pipeline, you can use the <a href="https://cdn.vectorly.io/upscaler/docs/latest/vectorlyUpscalerCore.html">vectorly-core library</a>.</p>

					<p>With the low level upscaling API, you have control over</p>
					<ul>
						<li>The Input source</li>
						<li>The destination</li>
						<li>When rendering happens</li>
					</ul>
					<p><strong>Setting a destination</strong></p>
					<p>Each Upscaler object is tied to an individual <code>canvas</code> element, and renders to that <code>canvas</code> element.</p>
					<p>You specify the <code>canvas</code> element you want to render the upscales to via the upscaler constructor</p>
					<pre><code>
   const upscaler = new vectorlyUpscaler.core();
   upscaler.load({w: videoWidth,
	          h: videoHeight,
	          renderSize: {w: videoWidth*2, h: videoHeight*2},
	          canvas: document.getElementById('your-canvas-element'),
	          networkParams : {name: 'model-name', tag: 'model-tag', version: 'model-version'},
	          token: "your-token"});
					</code></pre>
					<p>If you want to upscale multiple streams to different canvases, you will need to define a seperate upscaler for each <code>canvas</code> element.</p>
					<p><strong>Setting an input</strong></p>
					<p>At any time, you can set the input of the upscaler via the <code>upscaler.setInput()</code> method</p>
					<pre><code> upscaler.setInput(source); // Sets input element
</code></pre>
					<p>Accepted sources include</p>
					<ul>
						<li><code>HTMLImageElement</code></li>
						<li><code>HTMLCanvasElement</code></li>
						<li><code>HTMLVideoElement</code></li>
						<li><code>ImageData</code></li>
						<li><code>ImageBitmap</code></li>
						<li>Anything else that the <a href="https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/texImage2D" rel="nofollow">texImage2d</a> function accepts</li>
					</ul>
					<p><strong>Rendering</strong></p>
					<p>Finally, you can render using</p>
					<pre><code>upscaler.render();
</code></pre>
					<p>Which will run the AI upscaling process on the canvas</p>
					<p><strong>Styling &amp; Scaling</strong></p>
					<p>You need to set the input width and height of your input image or video streaming using the <code>w</code> and <code>h</code> properties in the constructor.</p>
					<p>Based on whether you are using  a 2X network, or 3X network, it will set the canvas.width and canvas.height property to 2x or 3x the specified <code>w</code> and <code>h</code>.</p>
					<p>If you want your canvas to be displayed at anything other than <code>2*w</code>by <code>2*h</code> on the screen, you should use CSS styling.</p>
					<pre><code>canvas.style.width = desiredWidth + "px";
canvas.style.height = desiredheight + "px";
</code></pre>
					<p>The browser will still upscale the image from <code>wxh</code> to  <code>2*w x 2*h</code>, but will then use CSS styling &amp; scaling (bicubic scaling) to scale the final output to the  height/width you specify via CSS.</p>


					<br></br>

					<section class="docs-section" id="item-upscale-mobile">
						<h2 class="section-heading">Mobile</h2>
						<h4 >Android</h4>





						<p>Our Android SDK works as a plugin to <a href="https://developer.android.com/guide/topics/media/exoplayer">ExoPlayer</a>. You will therefore need to use ExoPlayer, or an ExoPlayer derived player, in order upscale video.</p>



						<p>First, you'll need to include our SDK into your app's gradle file. You can import it from our Maven repository, as shown below.</p>



						<pre>
							 <code>
   repositories {
     google()
     jcenter()
     maven { url "http://maven.vectorly.io/artifactory/libs-release-local" }
   }
   dependencies {
      implementation 'io.vectorly.glnnrender:glnnrender:0.1.1'
   }
							 </code>
						 </pre>


						<p>
							You can then add the following imports into the activity which manages your ExoPlayer view
						</p>

						<pre>
							 <code>
   import io.vectorly.glnnrender.GlPlayerView;
   import io.vectorly.glnnrender.networks.NetworkTypes;
							 </code>
						 </pre>

						<p>
							Once the ExoPlayer view is set up, you can call set up the Upscaler as in the following example. You'll need to feed your API key, which you can get from the <a href="https://dashboard.vectorly.io">Vectorly dashboard</a>.
						</p>



						<pre>
							 <code>
   private GlPlayerView ePlayerView;

   private void setupUpscalerView() {

           String api_key = "...";
           ePlayerView = new GlPlayerView(this, api_key);
           ePlayerView.setSimpleExoPlayer(player);

           ePlayerView.setNetwork(NetworkTypes.DEFAULT, getApplicationContext());
            ePlayerView.setLayoutParams(new RelativeLayout.LayoutParams(ViewGroup.LayoutParams.MATCH_PARENT, ViewGroup.LayoutParams.MATCH_PARENT));
           ((MovieWrapperView) findViewById(R.id.layout_movie_wrapper)).addView(ePlayerView);
           ePlayerView.onResume();

    }
</code>
						 </pre>


						<p>We've created a full working example using our library, which you can find below</p>

						<p>
							<a href="https://github.com/Vectorly/android-demo" class="btn btn-success"><svg class="svg-inline--fa fa-file-code fa-w-16 mr-2" aria-hidden="true" focusable="false" data-prefix="fas" data-icon="file-code" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" data-fa-i2svg=""><path fill="currentColor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg>Example Repo</a>
						</p>



						<h4 >iOS</h4>
						<p>We plant to release an iOS SDK in Summer 2021</p>


					</section><!--//section-->

				</article><!--//docs-article-->


			    <article class="docs-article" id="section-demos">
				    <header class="docs-header">
					    <h1 class="docs-heading">Demos</h1>
					    <section class="docs-intro ">

							<p><b>Virtual Background demo</b></p>
							<p><a href="https://files.vectorly.io/demo/background/webrtc/index.html" target="_blank">Live Virtual Background Demo</a> </p>


							<b>AI Upscaling demos</b>


							<ul>
								<li> <a href="https://files.vectorly.io/demo/docs-demos/demo.html#jellyfish" target="_blank">Jellyfish</a></li>
								<li> <a href="https://files.vectorly.io/demo/docs-demos/demo.html#ducks" target="_blank">Ducks</a></li>
								<li> <a href="https://files.vectorly.io/demo/docs-demos/demo.html#tractor" target="_blank">Tractor</a></li>
								<li> <a href="https://files.vectorly.io/demo/docs-demos/demo.html#fish" target="_blank">Fish</a></li>

							</ul>


						</section><!--//docs-intro-->

				    </header>

			    </article><!--//docs-article-->


		        <article class="docs-article" id="section-performance">
				    <header class="docs-header">
					    <h1 class="docs-heading">Performance</h1>
					    <section class="docs-intro">
						    <p>When running AI filters on client-devices, the most practical challenge is client side performance, as it requires doing large numbers of computations. This can especially become an issue when dealing with low-end devices (such as entry-level smartphones).
							</p>

							<p>	Accordingly, we have focused a great deal on making our AI models as efficient as possible, to enable good quality outputs while still maintaining good client-side rendering performance on low-end devices.
							</p>
						</section><!--//docs-intro-->
				    </header>

					<section class="docs-section" id="item-background-performance">

						<h2 class="section-heading">Background Segmentation</h2>
						<p>Our background filter is based on the <a href="https://drive.google.com/file/d/1lnP1bRi9CSqQQXUHa13159vLELYDgDu0/preview">Google Meet model</a>, and run using <a href="https://google.github.io/mediapipe/" >Media Pipe</a> the same way it is run in Google Meet. Google Meet's background-segmentation model runs entirely on the CPU, which does require performance considerations.</p>

						<figure class="figure docs-figure py-3">
							<img class="figure-img img-fluid" src="assets/images/framerate-background.svg" alt="" style="width: 800px;">
						</figure>


						<figure class="figure docs-figure py-3">
							<img class="figure-img img-fluid" src="assets/images/cpu-usage-background.svg" alt="" style="width: 800px;">
						</figure>

						<p>You can measure the fps on any given device by adding the <code>analyticsEnabled</code> flag as <code>true</code> in the configuration parameters.


						<pre>
							 <code>
  const config = {
	   token: '...',
	   type: 'blur',
	   analyticsEnabled: true
   };

   const filter = BackgroundFilter(video, config);
							 </code>
						 </pre>

						</p>
						<h4  id="item-background-performance-considerations">Performance Considerations</h4>
						<p>We recommend only running the Web Background filters library for desktop users. The performance is considerably worse on Mobile because because the overhead of communicating between the browser and GPU is much higher on mobile devices.</p>

						<p>We expect the performance to rival or exceed desktop clients with a Native Android SDK, as is the case for our <a href="#item-upscale-performance" >AI Upscaler Android SDK</a>. We are planning to develop a Background Filters Android and iOS SDK in Q3 2021.</p>
						<p>Additionally, we are working on a fully WebGL/OpenGL implementation of the Background Filter, which should greatly exceed the performance of Google's Meet model.</p>






					</section><!--//section-->
				     <section class="docs-section" id="item-upscale-performance">

						 <h2 class="section-heading">AI Upscaling</h2>

						<p>The primary "cost" to doing super-resolution is computational complexity. While we have put a lot of work into making super resolution feasible on client devices, it is still something which needs to be managed. Here, we provide some initial performance benchmarks for the same demos shown above, in the demos sections.</p>

						 <figure class="figure docs-figure py-3">
							 <img class="figure-img img-fluid" src="assets/images/framerate-upscaling.svg" alt="" style="width: 800px;">
						 </figure>


						 <figure class="figure docs-figure py-3">
							 <img class="figure-img img-fluid" src="assets/images/cpu-usage-upscaling.svg" alt="" style="width: 800px;">
						 </figure>

						 <h4  id="item-upscale-performance-considerations">Performance Considerations</h4>

						 <p>AI Upscaling does require some computational effort, however it is mostly on the graphics card, so AI Upscaling's impact on CPU is limited. The amount of computation (and therefore the framerate / performance) depends on the size of input video you are upscaling</p>

						 <p>The following table should give a rough idea performance for different input video resolutions. These results are only for Web environments. Our mobile SDKs will have access to more powerful native libraries, enabling significantly better performance.</p>

						 <div class="table-responsive my-4">
							 <table class="table table-striped">

								 <tr>
									 <th scope="col"></th>
									 <th scope="col">240p -> 480p/720p</th>
									 <th scope="col">360p -> 720p/1080p</th>
									 <th scope="col">480p -> 960p/1440p</th>
								 </tr>

								 <tbody>


								 <tr>
									 <th scope="row">High End Smartphone</th>
									 <td>120 fps</td>
									 <td>40 fps</td>
									 <td>14fps</td>
								 </tr>

								 <tr>
									 <th scope="row">Mid-range Smartphone</th>

									 <td>80 fps</td>
									 <td>28 fps</td>
									 <td>9 fps</td>
								 </tr>

								 <tr>
									 <th scope="row">Low-End Smartphone</th>

									 <td>20fps</td>
									 <td>6fps</td>
									 <td>3fps</td>
								 </tr>

								 <tr>

									 <th scope="row">Mid-range Laptop</th>

									 <td>100fps</td>
									 <td>35fps</td>
									 <td>8fps</td>
								 </tr>

								 <tr>

									 <th scope="row">GPU Desktop</th>

									 <td>200+fps</td>
									 <td>200+fps</td>
									 <td>80 fps</td>
								 </tr>


								 </tbody>
							 </table>
						 </div>


						 <p>You can measure the fps on any given device by adding the <code>analyticsEnabled</code> flag as <code>true</code> in the configuration parameters.


						 <pre>
							 <code>
  const config = {
	   token: '...',
	   analyticsEnabled: true
   };

   const upscaler = vectorlyUpscaler(video, config);
							 </code>
						 </pre>

						 </p>


						 <p>You can then measure the fps at any time with <code>upscaler.metrics.fps</code> property. The fps number provided by <code>upscaler.metrics.fps</code> will not exceed the source video's frame rate because we only render when a video frame changes. </p>

						 <p>
							 It's recommended to stick to 240p or 360p inputs, as mid-range devices tend to struggle with larger inputs. You can also <a href="#item-upscale-controls">disable upscaling</a>  if the fps gets too low.</p>


						<h4 >Quality</h4>
						<p>The primary benefit of Super resolution is to increase video quality. Using the original high-resolution video as a reference, we can use traditional video quality metrics like VMAF to quantify the quality improvement of Super Resolution, when compared to normal bicubic upscaling of the downsampled / low-resolution video content.</p>


						<figure class="figure docs-figure py-3">
							<img class="figure-img img-fluid" src="assets/images/quality-comparison.svg" alt="" style="width: 800px;">
						</figure>


						<p>Our general AI upscaler filter generally achieves a 10 to 15 point VMAF improvement compared to bicubic scaling. With <a href="#item-upscale-models"> content-specific AI models</a>, or heavier models, we will likely be able to achieve further quality gains. We are currently working on releasing quality comparisons for content specific models.</p>


						<h5>Quality visualization</h5>

						<p>For reference, below are side by side comparisons of bicubic upscaling of the low-resolution original / Super resolution of the low-resolution / High resolution original </p>

						<p style="text-decoration: underline">Jellyfish</p>
						<figure class="figure docs-figure py-3">

							<div class="table-responsive my-4">
								<table class="table" style="border-color: white">

									<tbody >
									<tr>

										<td style="border-top: white;"><img class="figure-img img-fluid" src="assets/images/jellyfish-240p.png" alt="" style="height: 250px;"></td>
										<td style="border-top: white;"><img class="figure-img img-fluid" src="assets/images/jellyfish-upscaled.png" alt="" style="height: 250px;"></td>
										<td style="border-top: white;"><img class="figure-img img-fluid" src="assets/images/jellyfish-720p.png" alt="" style="height: 250px;"></td>
									</tr>
									<tr style="text-align: center">
										<td style="border-top: white;"><figcaption class="figure-caption mt-3">Bicubic (240p)</figcaption></td>
										<td style="border-top: white;"><figcaption class="figure-caption mt-3">240p upscaled to 720p</figcaption></td>
										<td style="border-top: white;"><figcaption class="figure-caption mt-3">Original 720p</figcaption></td>
									</tr>
									</tbody>
								</table>
							</div>

						</figure>

						<p style="text-decoration: underline">Ducks</p>
						<figure class="figure docs-figure py-3">

							<div class="table-responsive my-4">
								<table class="table" style="border-color: white">

									<tbody >
									<tr>

										<td style="border-top: white;"><img class="figure-img img-fluid" src="assets/images/ducks-240p.png" alt="" style="height: 250px;"></td>
										<td style="border-top: white;"><img class="figure-img img-fluid" src="assets/images/ducks-upscaled.png" alt="" style="height: 250px;"></td>
										<td style="border-top: white;"><img class="figure-img img-fluid" src="assets/images/ducks-720p.png" alt="" style="height: 250px;"></td>
									</tr>
									<tr style="text-align: center">
										<td style="border-top: white;"><figcaption class="figure-caption mt-3">Bicubic (240p)</figcaption></td>
										<td style="border-top: white;"><figcaption class="figure-caption mt-3">240p upscaled to 720p</figcaption></td>
										<td style="border-top: white;"><figcaption class="figure-caption mt-3">Original 720p</figcaption></td>
									</tr>
									</tbody>
								</table>
							</div>

						</figure>


						<p style="text-decoration: underline;">Tractor</p>
						<figure class="figure docs-figure py-3">

							<div class="table-responsive my-4">
								<table class="table" style="border-color: white">

									<tbody >
									<tr>

										<td style="border-top: white;"><img class="figure-img img-fluid" src="assets/images/tractor-240p.png" alt="" style="height: 250px;"></td>
										<td style="border-top: white;"><img class="figure-img img-fluid" src="assets/images/tractor-upscaled.png" alt="" style="height: 250px;"></td>
										<td style="border-top: white;"><img class="figure-img img-fluid" src="assets/images/tractor-720p.png" alt="" style="height: 250px;"></td>
									</tr>
									<tr style="text-align: center">
										<td style="border-top: white;"><figcaption class="figure-caption mt-3">Bicubic (240p)</figcaption></td>
										<td style="border-top: white;"><figcaption class="figure-caption mt-3">240p upscaled to 720p</figcaption></td>
										<td style="border-top: white;"><figcaption class="figure-caption mt-3">Original 720p</figcaption></td>
									</tr>
									</tbody>
								</table>
							</div>

						</figure>

					</section><!--//section-->

			    </article><!--//docs-article-->


			    <footer class="footer">
				    <div class="container text-center py-5">

				        <ul class="social-list list-unstyled pt-4 mb-0">
							<li class="list-inline-item"><a href="https://github.com/Vectorly"><i class="fab fa-github fa-fw"></i></a></li>
							<li class="list-inline-item"><a href="https://www.linkedin.com/company/vectorly"><i class="fab fa-linkedin fa-fw"></i></a></li>
							<li class="list-inline-item"><a href="https://angel.co/vectorly"><i class="fab fa-angellist fa-fw"></i></a></li>
				        </ul><!--//social-list-->
				    </div>
			    </footer>
		    </div>
	    </div>
    </div><!--//docs-wrapper-->



    <!-- Javascript -->
    <script src="assets/plugins/jquery-3.4.1.min.js"></script>
    <script src="assets/plugins/popper.min.js"></script>
    <script src="assets/plugins/bootstrap/js/bootstrap.min.js"></script>


    <!-- Page Specific JS -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.8/highlight.min.js"></script>
    <script src="assets/js/highlight-custom.js"></script>
    <script src="assets/plugins/jquery.scrollTo.min.js"></script>
    <script src="assets/plugins/lightbox/dist/ekko-lightbox.min.js"></script>
    <script src="assets/js/docs.js"></script>




    <script type="text/javascript">
        window._mfq = window._mfq || [];
        (function() {
            var mf = document.createElement("script");
            mf.type = "text/javascript"; mf.defer = true;
            mf.src = "//cdn.mouseflow.com/projects/ade379db-9c1a-4bba-9bf0-a0fbf6ceb01e.js";
            document.getElementsByTagName("head")[0].appendChild(mf);
        })();
    </script>

</body>
</html>

